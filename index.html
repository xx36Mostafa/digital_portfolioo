<!DOCTYPE html>
<html lang="ar" dir="rtl">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ูุดุฑูุน Text Generation - ุงูุชูุซูู ุงููุงูู</title>
    <link
        href="https://fonts.googleapis.com/css2?family=Cairo:wght@300;400;600;700;900&family=IBM+Plex+Sans+Arabic:wght@300;400;600;700&display=swap"
        rel="stylesheet">
    <style>
        :root {
            --primary: #1a1a2e;
            --secondary: #16213e;
            --accent: #0f3460;
            --highlight: #e94560;
            --text: #f1f1f1;
            --text-dim: #b8b8b8;
            --code-bg: #0d1117;
            --success: #2ecc71;
            --warning: #f39c12;
            --info: #3498db;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'IBM Plex Sans Arabic', 'Cairo', sans-serif;
            background: linear-gradient(135deg, var(--primary) 0%, var(--secondary) 50%, var(--accent) 100%);
            color: var(--text);
            line-height: 1.8;
            min-height: 100vh;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 2rem;
        }

        header {
            text-align: center;
            padding: 4rem 2rem;
            background: linear-gradient(120deg, rgba(233, 69, 96, 0.1) 0%, rgba(15, 52, 96, 0.2) 100%);
            border-radius: 20px;
            margin-bottom: 3rem;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.3);
            animation: fadeInDown 0.8s ease;
        }

        h1 {
            font-family: 'Cairo', sans-serif;
            font-size: 3.5rem;
            font-weight: 900;
            background: linear-gradient(135deg, #e94560 0%, #f39c12 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 1rem;
            text-shadow: 0 0 30px rgba(233, 69, 96, 0.3);
        }

        .subtitle {
            font-size: 1.3rem;
            color: var(--text-dim);
            font-weight: 300;
        }

        nav {
            background: rgba(26, 26, 46, 0.8);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 1.5rem;
            margin-bottom: 3rem;
            position: sticky;
            top: 20px;
            z-index: 100;
            box-shadow: 0 5px 20px rgba(0, 0, 0, 0.3);
            animation: fadeIn 1s ease;
        }

        nav ul {
            list-style: none;
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 1rem;
        }

        nav a {
            color: var(--text);
            text-decoration: none;
            padding: 0.8rem 1.5rem;
            border-radius: 8px;
            transition: all 0.3s ease;
            font-weight: 600;
            background: rgba(255, 255, 255, 0.05);
        }

        nav a:hover {
            background: var(--highlight);
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(233, 69, 96, 0.4);
        }

        .section {
            background: rgba(26, 26, 46, 0.6);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 3rem;
            margin-bottom: 2rem;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.3);
            border: 1px solid rgba(255, 255, 255, 0.1);
            animation: fadeInUp 0.8s ease;
        }

        h2 {
            font-family: 'Cairo', sans-serif;
            font-size: 2.5rem;
            font-weight: 700;
            color: var(--highlight);
            margin-bottom: 2rem;
            padding-bottom: 1rem;
            border-bottom: 3px solid var(--highlight);
            display: inline-block;
        }

        h3 {
            font-size: 1.8rem;
            font-weight: 600;
            color: var(--info);
            margin: 2rem 0 1rem;
        }

        h4 {
            font-size: 1.4rem;
            font-weight: 600;
            color: var(--warning);
            margin: 1.5rem 0 1rem;
        }

        .code-block {
            background: var(--code-bg);
            border-radius: 12px;
            padding: 1.5rem;
            margin: 1rem 0;
            overflow-x: auto;
            border-right: 4px solid var(--highlight);
            font-family: 'Courier New', monospace;
            font-size: 0.95rem;
            line-height: 1.6;
            box-shadow: inset 0 2px 10px rgba(0, 0, 0, 0.5);
        }

        .code-block code {
            color: #7dd3fc;
        }

        .highlight {
            background: linear-gradient(120deg, rgba(233, 69, 96, 0.2) 0%, rgba(243, 156, 18, 0.2) 100%);
            padding: 0.3rem 0.6rem;
            border-radius: 5px;
            font-weight: 600;
        }

        .info-box {
            background: linear-gradient(135deg, rgba(52, 152, 219, 0.1) 0%, rgba(52, 152, 219, 0.05) 100%);
            border-right: 4px solid var(--info);
            border-radius: 10px;
            padding: 1.5rem;
            margin: 1.5rem 0;
        }

        .success-box {
            background: linear-gradient(135deg, rgba(46, 204, 113, 0.1) 0%, rgba(46, 204, 113, 0.05) 100%);
            border-right: 4px solid var(--success);
            border-radius: 10px;
            padding: 1.5rem;
            margin: 1.5rem 0;
        }

        .warning-box {
            background: linear-gradient(135deg, rgba(243, 156, 18, 0.1) 0%, rgba(243, 156, 18, 0.05) 100%);
            border-right: 4px solid var(--warning);
            border-radius: 10px;
            padding: 1.5rem;
            margin: 1.5rem 0;
        }

        ul,
        ol {
            margin: 1rem 0 1rem 2rem;
        }

        li {
            margin: 0.5rem 0;
            color: var(--text-dim);
        }

        strong {
            color: var(--highlight);
            font-weight: 700;
        }

        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 2rem 0;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 12px;
            overflow: hidden;
        }

        .comparison-table th {
            background: var(--highlight);
            color: white;
            padding: 1rem;
            text-align: right;
            font-weight: 700;
        }

        .comparison-table td {
            padding: 1rem;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        .comparison-table tr:hover {
            background: rgba(233, 69, 96, 0.1);
        }

        footer {
            text-align: center;
            padding: 3rem 2rem;
            margin-top: 4rem;
            color: var(--text-dim);
            border-top: 1px solid rgba(255, 255, 255, 0.1);
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
            }

            to {
                opacity: 1;
            }
        }

        @keyframes fadeInDown {
            from {
                opacity: 0;
                transform: translateY(-30px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .badge {
            display: inline-block;
            padding: 0.4rem 1rem;
            border-radius: 20px;
            font-size: 0.85rem;
            font-weight: 600;
            margin: 0.3rem;
        }

        .badge-success {
            background: var(--success);
            color: white;
        }

        .badge-warning {
            background: var(--warning);
            color: white;
        }

        .badge-info {
            background: var(--info);
            color: white;
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 2rem;
            }

            h2 {
                font-size: 1.8rem;
            }

            .section {
                padding: 1.5rem;
            }

            nav ul {
                flex-direction: column;
            }
        }
    </style>
</head>

<body>
    <div class="container">
        <header>
            <h1>๐ค ูุดุฑูุน Text Generation</h1>
            <p class="subtitle">ุชูุซูู ุดุงูู ูููุดุฑูุน - ููุงุฑูุฉ ุจูู ูููุฐุฌูู ูู ุงูู Chatbot</p>
        </header>

        <nav>
            <ul>
                <li><a href="#overview">ูุธุฑุฉ ุนุงูุฉ</a></li>
                <li><a href="#eda-results">ูุชุงุฆุฌ EDA</a></li>
                <li><a href="#eda">EDA - ุงูุชุญููู ุงูุงุณุชูุดุงูู</a></li>
                <li><a href="#data-cleaning">ุชูุธูู ุงูุจูุงูุงุช</a></li>
                <li><a href="#preprocessing">ุงููุนุงูุฌุฉ ุงููุณุจูุฉ</a></li>
                <li><a href="#vectorization">Vectorization</a></li>
                <li><a href="#models">ุงูููุงุฑูุฉ ุจูู ุงููููุฐุฌูู</a></li>
                <li><a href="#concepts">ุงูููุงููู ุงูุฃุณุงุณูุฉ</a></li>
                <li><a href="#textblob">ููุชุจุฉ TextBlob</a></li>
                <li><a href="#old-tasks">Old Tasks</a></li>
            </ul>
        </nav>

        <!-- ูุธุฑุฉ ุนุงูุฉ -->
        <section class="section" id="overview">
            <h2>๐ ูุธุฑุฉ ุนุงูุฉ ุนูู ุงููุดุฑูุน</h2>

            <p>ุงููุดุฑูุน ุนุจุงุฑุฉ ุนู ุจูุงุก <span class="highlight">Chatbot</span> ุจุงุณุชุฎุฏุงู ุชูููุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุชูููุฏ
                ุงููุตูุต. ุชู ุชุทููุฑ ูููุฐุฌูู ูุฎุชูููู:</p>

            <div class="info-box">
                <h3>ุงููููุฐุฌ ุงูุฃูู: Transformer Chatbot (final_chatbot)</h3>
                <p><strong>ุงููุตู:</strong> ูููุฐุฌ ูุจูู ูู ุงูุตูุฑ ุจุงุณุชุฎุฏุงู ุจููุฉ Transformer</p>
                <p><strong>Dataset:</strong> Cornell Movie-Dialogs Corpus</p>
                <p><strong>ุนุฏุฏ ุงููุญุงุฏุซุงุช:</strong> 221,616 ุณุคุงู-ุฌูุงุจ</p>
                <span class="badge badge-warning">ุงููุชุงุฆุฌ ูุงูุช ุนุดูุงุฆูุฉ</span>
            </div>

            <div class="success-box">
                <h3>ุงููููุฐุฌ ุงูุซุงูู: GPT-2 Fine-tuning (gpt2_chatbot_finetuning)</h3>
                <p><strong>ุงููุตู:</strong> Fine-tuning ุนูู ูููุฐุฌ GPT-2 ุงููุฏุฑุจ ูุณุจูุงู</p>
                <p><strong>Dataset:</strong> ููุณ ุงูู Dataset</p>
                <p><strong>ุนุฏุฏ ุงูุนููุงุช ููุชุฏุฑูุจ:</strong> 20,000 ูุญุงุฏุซุฉ</p>
                <span class="badge badge-success">ุงููุชุงุฆุฌ ูุงูุช ุฃูุถู ุจูุซูุฑ</span>
            </div>
        </section>

        <!-- EDA Section -->
        <section class="section" id="eda">
            <h2>๐ EDA - ุงูุชุญููู ุงูุงุณุชูุดุงูู ููุจูุงูุงุช</h2>

            <div class="warning-box">
                <h3>โ ูู ุนูููุง EDA ูู ุงููุดุฑูุนุ</h3>
                <p><strong>ูุงุ ุงูููุฏูู ูู ูุชุถููุง EDA</strong></p>
                <p>ุงูููุฏ ุฑุงุญ ูุจุงุดุฑุฉ ูู ุชุญููู ุงูุจูุงูุงุช โ ุงููุนุงูุฌุฉ โ ุงูุชุฏุฑูุจ</p>
            </div>

            <h3>๐ค ูู ูุงุฒู ูุถูู EDAุ</h3>

            <div class="info-box">
                <h4>ูููุดุฑูุน ุจุชุงุนู:</h4>
                <ul>
                    <li>โ <strong>ูุด ูุงุฒู ุถุฑูุฑู</strong> - ูุฃู ุงููุดุฑูุน Text Generation ูุด Classification</li>
                    <li>โ <strong>ููู ุฅุถุงูุชู ููุฒุฉ ูุจูุฑุฉ</strong> - ูุซุจุช ูููู ุงูุนููู ููุจูุงูุงุช ูู ุงูููุงูุดุฉ</li>
                    <li>๐ <strong>ูุณุงุนุฏ ูู ุชุจุฑูุฑ ุงููุฑุงุฑุงุช</strong> - ูุซู ุงุฎุชูุงุฑ max_length=60 ุฃู vocab_size</li>
                </ul>

                <h4>ูููุดุงุฑูุน ุจุดูู ุนุงู:</h4>
                <ul>
                    <li><strong>Classification/Regression:</strong> EDA <span class="highlight">ูุงุฒู ุถุฑูุฑู</span></li>
                    <li><strong>Text Generation:</strong> ุงุฎุชูุงุฑู ููู ููุตู ุจู ุจุดุฏุฉ</li>
                    <li><strong>Research Projects:</strong> ุฏุงููุงู ุถุฑูุฑู</li>
                </ul>
            </div>

            <h3>โ ูููุน ูุถููู ุฏูููุชูุ</h3>

            <div class="success-box">
                <p><strong>ุฃููุฉ ูููุน! ูููููู ุณูู ูุณุฑูุน (30-60 ุฏูููุฉ)</strong></p>

                <h4>๐ ููู ูุถูููุ</h4>
                <p>ุฃุถู cell ุฌุฏูุฏุฉ ูู ุงูู notebook ุจุนููุงู <code>Exploratory Data Analysis</code></p>
                <p><strong>ุงูุชุฑุชูุจ ุงูุตุญูุญ:</strong></p>
                <div class="code-block">
                    <code>1. Load Dataset โ
2. Parse Conversations โ
3. ๐ EDA โ ููุง
4. Text Preprocessing โ
5. Tokenization โ
6. Model Building โ</code>
                </div>
            </div>

            <h3>๐ ุฅูู ุงููู ูุถููู ุจุงูุธุจุทุ</h3>

            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>ุงูุชุญููู</th>
                        <th>ุงููุตู</th>
                        <th>ุงูููุฏ ุงููุทููุจ</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>1. Dataset Overview</strong></td>
                        <td>ุฅุญุตุงุฆูุงุช ุนุงูุฉ</td>
                        <td>ุนุฏุฏ ุงูุฃุณุฆูุฉุ ุงูุฃุฌูุจุฉุ ุงููููุงุช ุงููุฑูุฏุฉ</td>
                    </tr>
                    <tr>
                        <td><strong>2. Text Length</strong></td>
                        <td>ุฅุญุตุงุฆูุงุช ุงูุทูู</td>
                        <td>Mean, Median, Std, Min, Max</td>
                    </tr>
                    <tr>
                        <td><strong>3. Distribution</strong></td>
                        <td>ุชูุฒูุน ุงูุฃุทูุงู</td>
                        <td>Histograms ูุทูู ุงูุฌูู</td>
                    </tr>
                    <tr>
                        <td><strong>4. Word Frequency</strong></td>
                        <td>ุงููููุงุช ุงูุฃูุซุฑ ุชูุฑุงุฑุงู</td>
                        <td>Top 20 words + Bar chart</td>
                    </tr>
                    <tr>
                        <td><strong>5. Vocabulary</strong></td>
                        <td>ุชุญููู ุงูููุฑุฏุงุช</td>
                        <td>Unique words, Vocabulary richness</td>
                    </tr>
                    <tr>
                        <td><strong>6. Punctuation</strong></td>
                        <td>ุนูุงูุงุช ุงูุชุฑููู</td>
                        <td>ูุณุจุฉ ุงูุฌูู ุจูุง ?, !, commas</td>
                    </tr>
                    <tr>
                        <td><strong>7. Short/Long</strong></td>
                        <td>ุงูุฌูู ุงููุตูุฑุฉ/ุงูุทูููุฉ</td>
                        <td>ุนุฏุฏ ุงูุฌูู <3 ูููุงุช ู>30 ูููุฉ</td>
                    </tr>
                    <tr>
                        <td><strong>8. Samples</strong></td>
                        <td>ุฃูุซูุฉ ุนุดูุงุฆูุฉ</td>
                        <td>5-10 ูุญุงุฏุซุงุช ูุฃูุซูุฉ</td>
                    </tr>
                    <tr>
                        <td><strong>9. Box Plots</strong></td>
                        <td>ููุงุฑูุฉ ุงูุชูุฒูุนุงุช</td>
                        <td>Questions vs Answers</td>
                    </tr>
                </tbody>
            </table>

            <h3>๐ก ุฃูุซูุฉ ุนูู ุงูููุฏ</h3>

            <h4>1๏ธโฃ Basic Statistics:</h4>
            <div class="code-block">
                <code>import numpy as np
question_lengths = [len(q.split()) for q in questions_clean]
answer_lengths = [len(a.split()) for a in answers_clean]

print(f"Questions - Mean: {np.mean(question_lengths):.2f}")
print(f"Questions - Median: {np.median(question_lengths):.0f}")
print(f"Answers - Mean: {np.mean(answer_lengths):.2f}")</code>
            </div>

            <h4>2๏ธโฃ Distribution Plot:</h4>
            <div class="code-block">
                <code>import matplotlib.pyplot as plt

plt.figure(figsize=(15, 5))
plt.subplot(1, 2, 1)
plt.hist(question_lengths, bins=50, color='skyblue')
plt.title('Question Length Distribution')
plt.xlabel('Words')
plt.subplot(1, 2, 2)
plt.hist(answer_lengths, bins=50, color='lightcoral')
plt.title('Answer Length Distribution')
plt.show()</code>
            </div>

            <h4>3๏ธโฃ Word Frequency:</h4>
            <div class="code-block">
                <code>from collections import Counter

all_words = []
for q in questions_clean:
    all_words.extend(q.split())
for a in answers_clean:
    all_words.extend(a.split())

word_freq = Counter(all_words)
most_common = word_freq.most_common(20)

for word, count in most_common:
    print(f"{word:15s} : {count:,}")</code>
            </div>

            <h3>๐ฏ ุงููุงุฆุฏุฉ ูู EDA ูู ุงูููุงูุดุฉ</h3>

            <div class="success-box">
                <h4>ุงุณุชุฎุฏู ูุชุงุฆุฌ EDA ูุชุจุฑูุฑ ูุฑุงุฑุงุชู:</h4>
                <ul>
                    <li><strong>Max Length = 60:</strong> "ุจูุงุกู ุนูู EDAุ 95% ูู ุงูุฌูู ุฃูู ูู 60 ูููุฉ"</li>
                    <li><strong>Vocab Size = 20,000:</strong> "ุงููููุงุช ุงููุงุฏุฑุฉ (ูุฑุฉ ูุงุญุฏุฉ) ุชุดูู ุถูุถุงุก ููุท"</li>
                    <li><strong>Architecture Choice:</strong> "ุชูุฒูุน ุงูุฃุณุฆูุฉ ูุงูุฃุฌูุจุฉ ูุชุดุงุจูุ ูุฐุง ุงุณุชุฎุฏููุง
                        Encoder-Decoder"</li>
                    <li><strong>Short Responses:</strong> "15% ูู ุงูุฑุฏูุฏ ูุตูุฑุฉ ุฌุฏุงูุ ูุฐุง ุงููููุฐุฌ ุฃุญูุงูุงู ูููุฏ ุฑุฏูุฏ
                        ูุตูุฑุฉ"</li>
                </ul>
            </div>

            <div class="warning-box">
                <h4>โฑ๏ธ ุงูููุช ุงููุทููุจ:</h4>
                <p>ุฅุถุงูุฉ EDA ูุงูู ูุณุชุบุฑู <strong>30-60 ุฏูููุฉ</strong></p>
                <p>ุงูุนุงุฆุฏ: ููู ุฃุนูู ููุจูุงูุงุช + ุฅููุงููุฉ ุชุจุฑูุฑ ูู ูุฑุงุฑ + ุงูุทุจุงุน ุงุญุชุฑุงูู</p>
            </div>
        </section>

        <!-- ุชูุธูู ุงูุจูุงูุงุช -->

        <!-- ูุณู ูุชุงุฆุฌ EDA ุงููุนููุฉ -->
        <section class="section" id="eda-results">
            <h2>๐ ูุชุงุฆุฌ EDA ุงููุนููุฉ ูู ุงููุดุฑูุน</h2>

            <div class="success-box">
                <h3>โ ุชู ุฅุถุงูุฉ EDA ูููุดุฑูุน!</h3>
                <p>ุจุนุฏ ุฅุถุงูุฉ ุงูู EDA cellsุ ุญุตููุง ุนูู ูุชุงุฆุฌ ุญููููุฉ ูู ุงูุจูุงูุงุช</p>
                <p><strong>ุฏู ุงููุชุงุฆุฌ ุงููุนููุฉ ุงููู ุทูุนุช ูู ุชุดุบูู ุงูููุฏ:</strong></p>
            </div>

            <h3>1๏ธโฃ ุฅุญุตุงุฆูุงุช Dataset ุงูุฃุณุงุณูุฉ</h3>
            <div class="code-block">
                <code>Total movie lines: 304,713
Total conversations: 83,097
Total question-answer pairs: 221,616</code>
            </div>

            <div class="info-box">
                <h4>๐ก ูุงุฐุง ูุนูู ูุฐุงุ</h4>
                <ul>
                    <li><strong>304,713 ุณุทุฑ</strong> ูู ููู movie_lines - ุฏู ูู ุฌูู ุงูุฃููุงู</li>
                    <li><strong>83,097 ูุญุงุฏุซุฉ</strong> - ูู ูุญุงุฏุซุฉ ูููุง ุฌููุชูู ุฃู ุฃูุซุฑ</li>
                    <li><strong>221,616 ุฒูุฌ ุณุคุงู-ุฌูุงุจ</strong> - ุฏู ุงููู ููุณุชุฎุฏููุง ูุนูุงู ููุชุฏุฑูุจ</li>
                </ul>
                <p><strong>ุงููุงุฆุฏุฉ:</strong> ุนุฑููุง ุฅู ุนูุฏูุง ุจูุงูุงุช ูุชูุฑ (221K pairs) ูุงููุฉ ููุชุฏุฑูุจ!</p>
            </div>

            <h3>2๏ธโฃ ุชุญููู ุฃุทูุงู ุงููุตูุต (Text Lengths)</h3>

            <h4>ุฃุทูุงู ุงูุฃุณุฆูุฉ (Questions):</h4>
            <div class="code-block">
                <code>Min: 0 words
Max: 313 words
Median (50th percentile): 7 words
75th percentile: 13 words
90th percentile: 22 words
95th percentile: 31 words
99th percentile: 55 words</code>
            </div>

            <h4>ุฃุทูุงู ุงูุฃุฌูุจุฉ (Answers):</h4>
            <div class="code-block">
                <code>Min: 0 words
Max: 556 words
Median (50th percentile): 7 words
75th percentile: 13 words
90th percentile: 23 words
95th percentile: 32 words
99th percentile: 58 words</code>
            </div>

            <div class="success-box">
                <h4>๐ ุงูุชูุตูุฉ ุงูุฐููุฉ:</h4>
                <div class="code-block">
                    <code>Recommended max_length for questions: 31 words
Recommended max_length for answers: 32 words
Overall recommended max_length: 32 words</code>
                </div>
                <p><strong>๐ก ูุงุฐุง ูุนูู ุงูู 95th percentileุ</strong></p>
                <ul>
                    <li>95% ูู ุงูุฃุณุฆูุฉ ุทูููุง 31 ูููุฉ ุฃู ุฃูู</li>
                    <li>95% ูู ุงูุฃุฌูุจุฉ ุทูููุง 32 ูููุฉ ุฃู ุฃูู</li>
                    <li>ูู ุงุณุชุฎุฏููุง max_length = 32ุ ููุบุทู 95% ูู ุงูุจูุงูุงุช</li>
                    <li>ุงูู 5% ุงูุจุงููุฉ (ุงูุฌูู ุงูุทูููุฉ ุฌุฏุงู) ูุชุชูุทุน</li>
                </ul>

                <p><strong>โ๏ธ ููุงุฑูุฉ ูุน ุงููุดุฑูุน ุงูุฃุตูู:</strong></p>
                <p>ูู ุงููุดุฑูุน ุงุณุชุฎุฏููุง <code>max_length = 60</code> ุจุฏูู EDA</p>
                <p>ููู ุงูู EDA ุจูููููุง ุฅู <code>max_length = 32</code> ูุงูู!</p>
                <p><strong>ุงููุงุฆุฏุฉ:</strong> ุชูููุฑ Memory ู ุณุฑุนุฉ ุฃูุจุฑ ูู ุงูุชุฏุฑูุจ ๐</p>
            </div>

            <h3>3๏ธโฃ ุชุญููู ุงูููุฑุฏุงุช (Vocabulary Analysis)</h3>
            <div class="code-block">
                <code>Total words (with repetition): 4,909,720
Unique words (vocabulary size): 49,045
Vocabulary richness: 1.00%</code>
            </div>

            <div class="info-box">
                <h4>๐ก ุดุฑุญ ุงููุชุงุฆุฌ:</h4>
                <ul>
                    <li><strong>4.9 ููููู ูููุฉ</strong> - ูุฌููุน ูู ุงููููุงุช ูู ูู ุงููุญุงุฏุซุงุช</li>
                    <li><strong>49,045 ูููุฉ ูุฑูุฏุฉ</strong> - ุญุฌู ุงูู Vocabulary ุงูุญูููู</li>
                    <li><strong>1% Richness</strong> - ูุนูุงูุง ูู ุชูุฑุงุฑ ูุจูุฑ (ููุณ ุงููููุงุช ุจุชุชูุฑุฑ ูุชูุฑ)</li>
                </ul>

                <p><strong>โ๏ธ ููุงุฑูุฉ ูุน ุงููุดุฑูุน:</strong></p>
                <p><strong>ุงููููุฐุฌ ุงูุฃูู:</strong> ุงุณุชุฎุฏู 48,895 ูููุฉ (ูุฑูุจ ุฌุฏุงู!)</p>
                <p><strong>ุงููููุฐุฌ ุงูุซุงูู:</strong> GPT-2 ุนูุฏู 50,257 token</p>
                <p><strong>ุงููุงุฆุฏุฉ:</strong> ุนุฑููุง ุฅู ุงูู vocab_size ูู ุงููุดุฑูุน ูุงู ููุงุณุจ โ</p>
            </div>

            <h3>4๏ธโฃ ุฃูุซุฑ 30 ูููุฉ ุดููุนุงู</h3>
            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>ุงูุชุฑุชูุจ</th>
                        <th>ุงููููุฉ</th>
                        <th>ุงูุชูุฑุงุฑ</th>
                        <th>ุงููุณุจุฉ</th>
                        <th>ุงูููุงุญุธุฉ</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>1</td>
                        <td><strong>you</strong></td>
                        <td>216,244</td>
                        <td>4.404%</td>
                        <td>๐ฅ ุงูุฃูุซุฑ ุงุณุชุฎุฏุงูุงู</td>
                    </tr>
                    <tr>
                        <td>2</td>
                        <td><strong>i</strong></td>
                        <td>209,034</td>
                        <td>4.258%</td>
                        <td>ุถูุงุฆุฑ ุงูุญูุงุฑ</td>
                    </tr>
                    <tr>
                        <td>3</td>
                        <td><strong>the</strong></td>
                        <td>141,339</td>
                        <td>2.879%</td>
                        <td>ุฃุฏุงุฉ ุชุนุฑูู</td>
                    </tr>
                    <tr>
                        <td>4</td>
                        <td><strong>to</strong></td>
                        <td>116,562</td>
                        <td>2.374%</td>
                        <td>ุญุฑู ุฌุฑ</td>
                    </tr>
                    <tr>
                        <td>5</td>
                        <td><strong>a</strong></td>
                        <td>103,508</td>
                        <td>2.108%</td>
                        <td>ุฃุฏุงุฉ ุชูููุฑ</td>
                    </tr>
                    <tr>
                        <td>6-10</td>
                        <td>s, it, t, that, and</td>
                        <td>-</td>
                        <td>-</td>
                        <td>ูููุงุช ุดุงุฆุนุฉ</td>
                    </tr>
                    <tr>
                        <td>12</td>
                        <td><strong>what</strong></td>
                        <td>56,304</td>
                        <td>1.147%</td>
                        <td>โ ูููุฉ ุณุคุงู ูููุฉ</td>
                    </tr>
                    <tr>
                        <td>23</td>
                        <td><strong>know</strong></td>
                        <td>32,510</td>
                        <td>0.662%</td>
                        <td>ูุนู ููู ูู ุงููุญุงุฏุซุงุช</td>
                    </tr>
                </tbody>
            </table>

            <div class="warning-box">
                <h4>๐ ููุงุญุธุงุช ูููุฉ:</h4>
                <ul>
                    <li><strong>Stop Words:</strong> ูุนุธู ุงููููุงุช ุงูุฃูุซุฑ ุดููุนุงู ูู Stop Words (you, i, the, to, a)</li>
                    <li><strong>s ู t:</strong> ุฏูู ุบุงูุจุงู ูุชูุฌุฉ contractions ูุซู "it's" โ "it" + "s"</li>
                    <li><strong>what:</strong> ุฃูุซุฑ ูููุฉ ุณุคุงู - ูุนูุงูุง ูู ุฃุณุฆูุฉ ูุชูุฑ ุจุชุจุฏุฃ ุจู "what"</li>
                </ul>

                <p><strong>๐ก ุงููุฑุงุฑ:</strong> ูู ุงูููุงุฐุฌ ุงูุญุฏูุซุฉ ุฒู GPT-2ุ ูุด ุจูุญุฐู Stop Words</p>
                <p><strong>ุงูุณุจุจ:</strong> ุงููููุฐุฌ ูุญุชุงุฌูุง ูููู ุงูุณูุงู ูุงูุชุฑููุจ ุงููุญูู</p>
            </div>

            <h3>5๏ธโฃ ุนูุงูุงุช ุงูุชุฑููู (Punctuation)</h3>
            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>ุงูุนูุงูุฉ</th>
                        <th>ุงูุนุฏุฏ</th>
                        <th>ุงูุงุณุชุฎุฏุงู</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Periods (.)</td>
                        <td>718,642</td>
                        <td>ุงูุฃูุซุฑ - ููุงูุฉ ุงูุฌูู</td>
                    </tr>
                    <tr>
                        <td>Apostrophes (')</td>
                        <td>312,091</td>
                        <td>Contractions (it's, don't)</td>
                    </tr>
                    <tr>
                        <td>Commas (,)</td>
                        <td>241,933</td>
                        <td>ูุตู ุงูุฌูู ูุงูุนุจุงุฑุงุช</td>
                    </tr>
                    <tr>
                        <td>Question marks (?)</td>
                        <td>163,744</td>
                        <td>ููุงูุฉ ุงูุฃุณุฆูุฉ</td>
                    </tr>
                    <tr>
                        <td>Exclamation marks (!)</td>
                        <td>50,562</td>
                        <td>ุงูุชุนุจูุฑ ุนู ุงููุดุงุนุฑ</td>
                    </tr>
                    <tr>
                        <td>Quotation marks (")</td>
                        <td>14,540</td>
                        <td>ุงูุญูุงุฑ ุงููุจุงุดุฑ</td>
                    </tr>
                </tbody>
            </table>

            <div class="info-box">
                <h4>๐ก ุงููุงุฆุฏุฉ:</h4>
                <p>ูุนุฑูุฉ ุนูุงูุงุช ุงูุชุฑููู ุจุชุณุงุนุฏูุง ูููู ุฅู:</p>
                <ul>
                    <li>163K ุนูุงูุฉ ุงุณุชููุงู = ูู ุฃุณุฆูุฉ ูุชูุฑ</li>
                    <li>312K apostrophe = ุงููุงุณ ุจุชุณุชุฎุฏู contractions ูุชูุฑ</li>
                    <li>ุฏุง ุจูุฃุซุฑ ุนูู ุงูู preprocessing ู tokenization</li>
                </ul>
            </div>

            <h3>6๏ธโฃ ูุญุต ุฌูุฏุฉ ุงูุจูุงูุงุช (Data Quality)</h3>
            <div class="code-block">
                <code>Empty questions: 197
Empty answers: 202
Very short questions (โค2 words): 33,781 (15.24%)
Very short answers (โค2 words): 35,375 (15.96%)
Very long questions (>50 words): 2,846 (1.28%)
Very long answers (>50 words): 3,306 (1.49%)
Texts with numbers: 2,476 (1.12%)</code>
            </div>

            <div class="warning-box">
                <h4>โ๏ธ ุงููุดุงูู ุงูููุชุดูุฉ:</h4>

                <p><strong>1. ูุตูุต ูุงุฑุบุฉ (Empty):</strong></p>
                <ul>
                    <li>197 ุณุคุงู ูุงุฑุบ + 202 ุฅุฌุงุจุฉ ูุงุฑุบุฉ = 399 ูุต ูุงุฑุบ</li>
                    <li><strong>ุงููุดููุฉ:</strong> ุงููุตูุต ุฏู ูุงููุงุด ูุงูุฏุฉ ููุชุฏุฑูุจ</li>
                    <li><strong>ุงูุญู:</strong> ูุงุฒู ูุญุฐููู ูู ุงูู preprocessing</li>
                </ul>

                <p><strong>2. ูุตูุต ูุตูุฑุฉ ุฌุฏุงู (Very Short):</strong></p>
                <ul>
                    <li>15% ูู ุงูุฃุณุฆูุฉ ู 16% ูู ุงูุฃุฌูุจุฉ ูุตูุฑุฉ ุฌุฏุงู (ูููุฉ ุฃู ุงุชููู)</li>
                    <li><strong>ุฃูุซูุฉ:</strong> "Yes.", "No.", "What?", "Okay."</li>
                    <li><strong>ุงูููุงุญุธุฉ:</strong> ุฏู ุทุจูุนูุฉ ูู ุงููุญุงุฏุซุงุชุ ููู ูููู ุชููู noise</li>
                    <li><strong>ุงููุฑุงุฑ:</strong> ูุฎูููุง - ุฏู ุฌุฒุก ุทุจูุนู ูู ุงููุญุงุฏุซุงุช</li>
                </ul>

                <p><strong>3. ูุตูุต ุทูููุฉ ุฌุฏุงู (Very Long):</strong></p>
                <ul>
                    <li>1.28% ูู ุงูุฃุณุฆูุฉ ู 1.49% ูู ุงูุฃุฌูุจุฉ ุทูููุฉ ุฌุฏุงู (>50 ูููุฉ)</li>
                    <li><strong>ุงููุดููุฉ:</strong> ุจุชุงุฎุฏ memory ูุชูุฑ ู ุตุนุจ ูุนุงูุฌุชูุง</li>
                    <li><strong>ุงูุญู:</strong> ุงูู max_length ูููุทุนูุง ุชููุงุฆูุงู</li>
                </ul>

                <p><strong>4. ูุตูุต ูููุง ุฃุฑูุงู:</strong></p>
                <ul>
                    <li>1.12% ููุท ูู ุงููุตูุต ูููุง ุฃุฑูุงู</li>
                    <li><strong>ุงูููุงุญุธุฉ:</strong> ูุณุจุฉ ููููุฉ - ูุด ูุดููุฉ ูุจูุฑุฉ</li>
                </ul>
            </div>

            <h3>7๏ธโฃ ุฃูุซูุฉ ูุนููุฉ ูู ุงููุญุงุฏุซุงุช</h3>

            <div class="code-block">
                <code><strong>Example 1:</strong>
Q: It's kind of late.
A: It got lonely upstairs. There's someone on the roof.
   (Q: 4 words, A: 9 words)

<strong>Example 2:</strong>
Q: You said nothing. You told me nothing.
A: You had left me! I kept silent out of rage.
   (Q: 7 words, A: 10 words)

<strong>Example 3:</strong>
Q: Well, maybe we'd better forget about it, then.
A: You can't prove it, can you? You're still trying to -- 
   marriage license! Did you say -- ?
   (Q: 8 words, A: 18 words)

<strong>Example 4:</strong>
Q: Watch out, you're on my hair!
A: Sorry. Move your hand to the left. There you go. Gorgeous.
   (Q: 6 words, A: 11 words)

<strong>Example 5:</strong>
Q: He's all right. He'd like to see you. But listen... What's 
   the law doing to me? Do they think I did it, or is it just 
   something else to pin on me?
A: I'd tell you if I knew. But I'm not in this. Ask the police.
   (Q: 32 words, A: 14 words)</code>
            </div>

            <div class="success-box">
                <h4>๐ก ููุงุญุธุงุช ุนูู ุงูุฃูุซูุฉ:</h4>
                <ul>
                    <li><strong>ุทุจูุนูุฉ:</strong> ุงููุญุงุฏุซุงุช ุชุจุฏู ุทุจูุนูุฉ ููุงูุนูุฉ</li>
                    <li><strong>ูุชููุนุฉ:</strong> ูู ุฌูู ูุตูุฑุฉ ูุทูููุฉ</li>
                    <li><strong>ุณูุงู:</strong> ูู ุฅุฌุงุจุฉ ูุฑุชุจุทุฉ ุจุงูุณุคุงู</li>
                    <li><strong>ูุดุงุนุฑ:</strong> ูู ุชุนุจูุฑุงุช ุนู ุงููุดุงุนุฑ (rage, sorry)</li>
                </ul>
                <p><strong>ุงููุงุฆุฏุฉ:</strong> ุฏู ุจุชุทูููุง ุฅู ุงูุจูุงูุงุช ูููุณุฉ ูููุงุณุจุฉ ููุชุฏุฑูุจ!</p>
            </div>

            <h3>๐ ุงูุฎูุงุตุฉ ุงูููุงุฆูุฉ ูู EDA</h3>

            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>ุงููููุงุณ</th>
                        <th>ุงููููุฉ ุงููุนููุฉ</th>
                        <th>ุงูุชุฃุซูุฑ ุนูู ุงููุดุฑูุน</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>ุนุฏุฏ ุฃุฒูุงุฌ ุงูุชุฏุฑูุจ</td>
                        <td>221,616</td>
                        <td>โ ูุงูู ุฌุฏุงู ููุชุฏุฑูุจ</td>
                    </tr>
                    <tr>
                        <td>Recommended max_length</td>
                        <td>32 ูููุฉ</td>
                        <td>โ๏ธ ุงุณุชุฎุฏููุง 60 - ูุงู ูููู ูููุฑ memory</td>
                    </tr>
                    <tr>
                        <td>Vocabulary Size</td>
                        <td>49,045 ูููุฉ</td>
                        <td>โ ูุฑูุจ ูู ุงููู ุงุณุชุฎุฏููุงู (48,895)</td>
                    </tr>
                    <tr>
                        <td>ูุชูุณุท ุทูู ุงูุณุคุงู</td>
                        <td>~7 ูููุงุช (median)</td>
                        <td>โ ุฌูู ูุตูุฑุฉ - ุณููุฉ ุงููุนุงูุฌุฉ</td>
                    </tr>
                    <tr>
                        <td>ูุตูุต ูุงุฑุบุฉ</td>
                        <td>399 ูุต</td>
                        <td>โ๏ธ ูุงุฒู ูุญุฐููู</td>
                    </tr>
                    <tr>
                        <td>ุฃูุซุฑ ูููุฉ</td>
                        <td>"you" (4.4%)</td>
                        <td>โ ุทุจูุนู - ูุญุงุฏุซุงุช ุจูู ุฃุดุฎุงุต</td>
                    </tr>
                    <tr>
                        <td>Vocabulary Richness</td>
                        <td>1.00%</td>
                        <td>โ ุชูุฑุงุฑ ุทุจูุนู ูููููุงุช</td>
                    </tr>
                </tbody>
            </table>

            <h3>๐ฏ ุงูุงุณุชูุชุงุฌุงุช ูุงูุชูุตูุงุช</h3>

            <div class="success-box">
                <h4>โ ูุง ูุงู ุตุญ ูู ุงููุดุฑูุน ุงูุฃุตูู:</h4>
                <ul>
                    <li>ุญุฌู ุงูุจูุงูุงุช ูุงู ููุชุงุฒ (221K pairs)</li>
                    <li>Vocabulary size ูุงู ููุงุณุจ (~49K)</li>
                    <li>ุงูุจูุงูุงุช ูุชููุนุฉ ูุทุจูุนูุฉ</li>
                    <li>ูุงููุด ูุดุงูู ูุจูุฑุฉ ูู ุฌูุฏุฉ ุงูุจูุงูุงุช</li>
                </ul>
            </div>

            <div class="warning-box">
                <h4>โ๏ธ ูุง ูุงู ูููู ูุญุณูู:</h4>
                <ul>
                    <li><strong>max_length:</strong> ูุงู ูููู ูุณุชุฎุฏู 32 ุจุฏู 60 โ ุชูููุฑ 47% memory!</li>
                    <li><strong>ุญุฐู ุงููุตูุต ุงููุงุฑุบุฉ:</strong> ุงูู 399 ูุต ุงููุงุฑุบูู ูุงููุง noise</li>
                    <li><strong>ูุนุงูุฌุฉ ุงููุตูุต ุงูุทูููุฉ:</strong> ุงูู 6K ูุต ุงููู ุฃุทูู ูู 50 ูููุฉ</li>
                </ul>
            </div>

            <div class="info-box">
                <h4>๐ก ุงูุฏุฑูุณ ุงููุณุชูุงุฏุฉ:</h4>
                <ol>
                    <li><strong>EDA ุถุฑูุฑู ูุจู ุฃู ูุดุฑูุน</strong> - ุจูููุฑ ููุช ููุฌููุฏ</li>
                    <li><strong>ุงูุจูุงูุงุช ุงูุญููููุฉ ุชุฎุชูู ุนู ุงูุชููุนุงุช</strong> - ูุงุฒู ูุดูููุง</li>
                    <li><strong>Percentiles ุฃูู ูู Max/Min</strong> - ุงูู 95th percentile ุฃูุถู ูู ุงูู Max</li>
                    <li><strong>Quality checks ุจุชูุดู ูุดุงูู</strong> - ุงููุตูุต ุงููุงุฑุบุฉ ูุงูุช ูุฎุชุจูุฉ</li>
                    <li><strong>Sample data ุจุชุนุทู feel</strong> - ุงูุฃูุซูุฉ ุจุชุทููุง ุนูู ุฌูุฏุฉ ุงูุจูุงูุงุช</li>
                </ol>
            </div>

            <h3>๐ ุงูุชุทุจูู ุงูุนููู - ููู ูุณุชุฎุฏู ุงููุชุงุฆุฌ ุฏู:</h3>

            <div class="code-block">
                <code># ุจูุงุกู ุนูู ูุชุงุฆุฌ EDAุ ุงูู parameters ุงููุซุงููุฉ:

MAX_LENGTH = 32  # ุจุฏู 60 - ูู ุงูู 95th percentile
VOCAB_SIZE = 50000  # ูุฑูุจ ูู ุงูู 49,045 ุงููุนูู
BATCH_SIZE = 64  # ูุนุชูุฏ ุนูู ุงูู memory ุงููุชุงุญ

# ุญุฐู ุงููุตูุต ุงููุงุฑุบุฉ
questions = [q for q in questions if len(q.strip()) > 0]
answers = [a for a in answers if len(a.strip()) > 0]

# Validation: ุชุฃูุฏ ุฅู ุงูุฃุทูุงู ูุชุทุงุจูุฉ
assert len(questions) == len(answers)</code>
            </div>

            <div class="success-box">
                <p><strong>๐ ุงูุฎูุงุตุฉ:</strong> EDA ูุนูุงู ุบููุฑ ููููุง ููุจูุงูุงุช ูุณุงุนุฏูุง ูุงุฎุฏ ูุฑุงุฑุงุช ุฃุฐูู!</p>
            </div>
        </section>


        <section class="section" id="data-cleaning">
            <h2>๐งน ููู ุชู ุชูุธูู ุงูุจูุงูุงุช (Data Cleaning)</h2>

            <h3>ูู ุงููููุฐุฌ ุงูุฃูู (Transformer):</h3>
            <div class="code-block">
                <code>def preprocess_text(text):
    text = text.lower().strip()
    text = re.sub(r"([?.!,])", r" \1 ", text)
    text = re.sub(r"[^a-zA-Z0-9?.!,]+", " ", text)
    text = re.sub(r'\s+', " ", text)
    return text.strip()</code>
            </div>

            <div class="info-box">
                <h4>ุงูุฎุทูุงุช ุงููุทุจูุฉ:</h4>
                <ol>
                    <li><strong>ุชุญููู ุฅูู ุฃุญุฑู ุตุบูุฑุฉ:</strong> <code>text.lower()</code> - ุชูุญูุฏ ุดูู ุงููุต</li>
                    <li><strong>ุฅุถุงูุฉ ูุณุงูุงุช ุญูู ุนูุงูุงุช ุงูุชุฑููู:</strong>
                        <code>re.sub(r"([?.!,])", r" \1 ", text)</code></li>
                    <li><strong>ุฅุฒุงูุฉ ุงูุฑููุฒ ุงูุฎุงุตุฉ:</strong> ุงูุงุญุชูุงุธ ููุท ุจุงูุญุฑูู ูุงูุฃุฑูุงู ูุนูุงูุงุช ุงูุชุฑููู ุงูุฃุณุงุณูุฉ
                    </li>
                    <li><strong>ุฅุฒุงูุฉ ุงููุณุงูุงุช ุงูุฒุงุฆุฏุฉ:</strong> <code>re.sub(r'\s+', " ", text)</code></li>
                    <li><strong>ุฅุถุงูุฉ tokens ุฎุงุตุฉ:</strong> <code>&lt;start&gt;</code> ู <code>&lt;end&gt;</code> ููู
                        ุฌููุฉ</li>
                </ol>
            </div>

            <h3>ูู ุงููููุฐุฌ ุงูุซุงูู (GPT-2):</h3>
            <div class="code-block">
                <code>def clean_text(text):
    text = text.lower().strip()
    text = re.sub(r"[^a-zA-Z0-9\s?.!,']", "", text)
    text = re.sub(r'\s+', ' ', text)
    return text</code>
            </div>

            <div class="success-box">
                <h4>ุงูุชุญุณููุงุช ูู ุงููููุฐุฌ ุงูุซุงูู:</h4>
                <ul>
                    <li>ุงุณุชุฎุฏุงู <span class="highlight">GPT2Tokenizer</span> ุงูุฌุงูุฒ ุจุฏูุงู ูู Keras Tokenizer</li>
                    <li>ุงูู Tokenizer ูุฏุฑุจ ูุณุจูุงู ุนูู ุจูุงูุงุช ุถุฎูุฉ</li>
                    <li>ูุชุนุงูู ุจุดูู ุฃูุถู ูุน ุงููููุงุช ุงููุงุฏุฑุฉ ูุงูุฌุฏูุฏุฉ</li>
                    <li>Format ุงููุญุงุฏุซุงุช ูู: <code>[ุงูุณุคุงู] [ุงูุฅุฌุงุจุฉ] &lt;|endoftext|&gt;</code></li>
                </ul>
            </div>
        </section>

        <!-- ุงููุนุงูุฌุฉ ุงููุณุจูุฉ -->
        <section class="section" id="preprocessing">
            <h2>โ๏ธ ุชูููุงุช ุงููุนุงูุฌุฉ ุงููุณุจูุฉ (NLP Preprocessing)</h2>

            <h3>1๏ธโฃ ูุงุฐุง ุนู POS Tagging (Part-of-Speech)?</h3>
            <div class="warning-box">
                <h4>โ ูู ูุณุชุฎุฏูู ูู ุงููุดุฑูุน</h4>
                <p><strong>ูุง ูู POS Taggingุ</strong></p>
                <p>ูู ุชุญุฏูุฏ ููุน ูู ูููุฉ ูู ุงูุฌููุฉ (ุงุณูุ ูุนูุ ุตูุฉุ ุฅูุฎ)</p>

                <p><strong>ูุซุงู:</strong></p>
                <div class="code-block">
                    <code>"I love machine learning"
I โ Pronoun
love โ Verb
machine โ Noun
learning โ Noun</code>
                </div>

                <p><strong>ููุงุฐุง ูู ูุณุชุฎุฏููุ</strong></p>
                <ul>
                    <li>ุงูููุงุฐุฌ ุงูุญุฏูุซุฉ ูุซู Transformer ู GPT-2 <strong>ุชุชุนูู ุงูุชุฑููุจ ุงููุญูู ุชููุงุฆูุงู</strong></li>
                    <li>ุงูู Self-Attention mechanism ูููู ุงูุนูุงูุงุช ุจูู ุงููููุงุช ุจุฏูู POS</li>
                    <li>POS ูููุฏ ุฃูุซุฑ ููููุงุฐุฌ ุงูุชูููุฏูุฉ (ูุซู RNN ุฃู LSTM ุงูุจุณูุท)</li>
                </ul>
            </div>

            <h3>2๏ธโฃ ูุงุฐุง ุนู Morphology (ุนูู ุงูุตุฑู)?</h3>
            <div class="warning-box">
                <h4>โ ูู ูุณุชุฎุฏูู ูู ุงููุดุฑูุน</h4>
                <p><strong>ูุง ูู Morphologyุ</strong></p>
                <p>ุฏุฑุงุณุฉ ุจููุฉ ุงููููุงุช ูุฃุดูุงููุง ุงููุฎุชููุฉ</p>

                <p><strong>ูุซุงู:</strong></p>
                <div class="code-block">
                    <code>run โ running, runs, ran
happy โ happier, happiest, happiness</code>
                </div>

                <p><strong>ุฃููุงุนู:</strong></p>
                <ul>
                    <li><strong>Stemming:</strong> ุงูุชุทุงุน ุงููููุฉ ูููุตูู ููุฌุฐุฑ (ุณุฑูุน ููู ุบูุฑ ุฏููู)</li>
                    <li><strong>Lemmatization:</strong> ุฅุฑุฌุงุน ุงููููุฉ ูุดูููุง ุงูุฃุณุงุณู (ุฏููู ููู ุฃุจุทุฃ)</li>
                </ul>

                <p><strong>ููุงุฐุง ูู ูุณุชุฎุฏููุ</strong></p>
                <ul>
                    <li>ููุงุฐุฌ Transformer ู GPT-2 ุชุณุชุฎุฏู <strong>Subword Tokenization</strong></li>
                    <li>ุชูุณูู ุงููููุงุช ุฅูู ุฃุฌุฒุงุก ุฃุตุบุฑ ูุนุทู ูุชุงุฆุฌ ุฃูุถู</li>
                    <li>ูุชุนุงูู ูุน ุงููููุงุช ุงููุงุฏุฑุฉ ูุงููุดุชูุงุช ุจุดูู ุทุจูุนู</li>
                </ul>
            </div>

            <h3>3๏ธโฃ Syntax Analysis (ุงูุชุญููู ุงููุญูู)</h3>
            <div class="info-box">
                <h4>โ ูู ูุณุชุฎุฏูู ุจุดูู ุตุฑูุญ</h4>
                <p><strong>ูุง ูู Syntax Analysisุ</strong></p>
                <p>ุชุญููู ุงูุชุฑููุจ ุงููุญูู ููุฌููุฉ ูุจูุงุก ุดุฌุฑุฉ ุงูุนูุงูุงุช ุจูู ุงููููุงุช</p>

                <p><strong>ูุซุงู:</strong></p>
                <div class="code-block">
                    <code>ุงูุฌููุฉ: "The cat sits on the mat"
ุงูุชุญููู:
    [Sentence]
       โโโ [Subject: The cat]
       โโโ [Verb: sits]
       โโโ [Prepositional Phrase: on the mat]</code>
                </div>

                <p><strong>ููู ูุชูุ</strong></p>
                <ul>
                    <li><strong>Dependency Parsing:</strong> ุจูุงุก ุดุฌุฑุฉ ุงูุนูุงูุงุช ุงููุญููุฉ</li>
                    <li><strong>Constituency Parsing:</strong> ุชูุณูู ุงูุฌููุฉ ุฅูู ููููุงุช ูุญููุฉ</li>
                </ul>

                <p><strong>ููุงุฐุง ูู ูุญุชุงุฌูุ</strong></p>
                <ul>
                    <li>ุงูู <strong>Multi-Head Attention</strong> ูู Transformer ูุชุนูู ูุฐู ุงูุนูุงูุงุช ุชููุงุฆูุงู</li>
                    <li>GPT-2 ูุฏุฑุจ ูุณุจูุงู ุนูู ููู ุงูุชุฑุงููุจ ุงููุญููุฉ ุงููุนูุฏุฉ</li>
                    <li>ุงูููุงุฐุฌ ุงูุญุฏูุซุฉ ูุง ุชุญุชุงุฌ parsing ุตุฑูุญ</li>
                </ul>
            </div>

            <h3>4๏ธโฃ Lemmatization (ุงูุฑุฌูุน ููุฌุฐุฑ ุงููุบูู)</h3>
            <div class="warning-box">
                <h4>โ ูู ูุณุชุฎุฏูู ูู ุงููุดุฑูุน</h4>
                <p><strong>ูุง ูู Lemmatizationุ</strong></p>
                <p>ุฅุฑุฌุงุน ุงููููุฉ ุฅูู ุดูููุง ุงูุฃุณุงุณู (ุงูุฌุฐุฑ) ูู ุงููุงููุณ ุจุดูู ุฏููู</p>

                <p><strong>ุฃูุซูุฉ:</strong></p>
                <div class="code-block">
                    <code>running โ run
better โ good
mice โ mouse
was โ be</code>
                </div>

                <p><strong>ููู ูุนููุ</strong></p>
                <ul>
                    <li>ูุณุชุฎุฏู ูุงููุณ ูุบูู ููุนูููุงุช ูุญููุฉ (POS)</li>
                    <li>ุฃุฏู ูู Stemming ููู ุฃุจุทุฃ</li>
                    <li>ููุชุจุงุช ูุซู NLTK ู SpaCy ุชููุฑู</li>
                </ul>

                <p><strong>ููุงุฐุง ูู ูุณุชุฎุฏููุ</strong></p>
                <ul>
                    <li><strong>Subword Tokenization</strong> ุฃูุถู ููููุงุฐุฌ ุงูุญุฏูุซุฉ</li>
                    <li>GPT-2 ููุณู ุงููููุงุช ุฅูู BPE tokens (Byte Pair Encoding)</li>
                    <li>ูุซุงู: <code>"running"</code> ูุฏ ุชุตุจุญ <code>["run", "ning"]</code></li>
                    <li>ูุฐุง ูุญุงูุธ ุนูู ุงููุนูู ููุชุนุงูู ูุน ุงููููุงุช ุงูุฌุฏูุฏุฉ</li>
                </ul>
            </div>
        </section>

        <!-- Vectorization -->
        <section class="section" id="vectorization">
            <h2>๐ข Vectorization - ุชุญููู ุงููุต ุฅูู ุฃุฑูุงู</h2>

            <div class="info-box">
                <h3>ูุง ูู Vectorizationุ</h3>
                <p>ุนูููุฉ ุชุญููู ุงููุตูุต ุฅูู ุชูุซูู ุฑููู ูููู ูููููุฐุฌ ูููู ูุงูุชุนุงูู ูุนู</p>
            </div>

            <h3>ุงูุฃููุงุน ุงููุฎุชููุฉ ูู Vectorization:</h3>

            <h4>1๏ธโฃ Bag of Words (BoW)</h4>
            <div class="code-block">
                <code>ุงูุฌูู:
- "I love machine learning"
- "I love coding"

Vocabulary: [I, love, machine, learning, coding]

ุงูุชูุซูู:
Sentence 1: [1, 1, 1, 1, 0]
Sentence 2: [1, 1, 0, 0, 1]</code>
            </div>

            <div class="warning-box">
                <h4>ุฃููุงุน BoW:</h4>

                <p><strong>ุฃ) Binary (ุซูุงุฆู):</strong></p>
                <ul>
                    <li>ุงููููุฉ 1 ุฅุฐุง ูุงูุช ุงููููุฉ ููุฌูุฏุฉุ 0 ุฅุฐุง ูู ุชูู</li>
                    <li>ูุง ููุชู ุจุงูุชูุฑุงุฑ</li>
                </ul>

                <p><strong>ุจ) Frequency (ุงูุชูุฑุงุฑ):</strong></p>
                <ul>
                    <li>ุนุฏุฏ ูุฑุงุช ุธููุฑ ูู ูููุฉ</li>
                    <li>ูุซุงู: "I love love coding" โ [1, 2, 0, 0, 1]</li>
                </ul>

                <p><strong>ุฌ) Counter (ุงูุนุฏุงุฏ):</strong></p>
                <ul>
                    <li>ููุณ Frequency ููู ุจุงุณุชุฎุฏุงู Counter ูู Python</li>
                    <li>ูุนุทู dictionary ุจุงูุชูุฑุงุฑุงุช</li>
                </ul>
            </div>

            <h4>2๏ธโฃ TF (Term Frequency)</h4>
            <div class="code-block">
                <code>TF = (ุนุฏุฏ ูุฑุงุช ุงููููุฉ ูู ุงููุซููุฉ) / (ุฅุฌูุงูู ุงููููุงุช ูู ุงููุซููุฉ)

ูุซุงู: "I love love coding"
TF(love) = 2 / 4 = 0.5</code>
            </div>

            <h4>3๏ธโฃ IDF (Inverse Document Frequency)</h4>
            <div class="code-block">
                <code>IDF = log(ุฅุฌูุงูู ุนุฏุฏ ุงููุซุงุฆู / ุนุฏุฏ ุงููุซุงุฆู ุงูุชู ุชุญุชูู ุงููููุฉ)

ุงููุฏู: ุชูููู ูุฒู ุงููููุงุช ุงูุดุงุฆุนุฉ (the, is, a)</code>
            </div>

            <h4>4๏ธโฃ TF-IDF</h4>
            <div class="code-block">
                <code>TF-IDF = TF ร IDF

ูุนุทู ูุฒู ุฃุนูู ูููููุงุช ุงููููุฉ ูุงููุงุฏุฑุฉ
ููุฒู ุฃูู ูููููุงุช ุงูุดุงุฆุนุฉ</code>
            </div>

            <div class="warning-box">
                <h3>โ ูู ุงุณุชุฎุฏููุง ูุฐู ุงูุทุฑู ูู ูุดุฑูุนูุงุ</h3>
                <p><strong>ูุงุ ูู ูุณุชุฎุฏููุง!</strong></p>
                <p><strong>ุงูุณุจุจ:</strong></p>
                <ul>
                    <li>ูุฐู ุทุฑู ุชูููุฏูุฉ ููู Text Classification ุฃู Information Retrieval</li>
                    <li>ูุง ุชุญูุธ ุชุฑุชูุจ ุงููููุงุช ููุง ุงูุณูุงู</li>
                    <li><strong>ุงุณุชุฎุฏููุง ุจุฏูุงู ูููุง:</strong></li>
                </ul>
            </div>

            <h3>โ ูุง ุงุณุชุฎุฏููุงู ูู ุงููุดุฑูุน:</h3>

            <div class="success-box">
                <h4>ุงููููุฐุฌ ุงูุฃูู (Transformer):</h4>
                <p><strong>Word Embeddings + Positional Encoding</strong></p>
                <div class="code-block">
                    <code># ุงูุณุทุฑ 250-260 ุชูุฑูุจุงู
embedding = Embedding(vocab_size, d_model)
pos_encoding = positional_encoding(max_seq_len, d_model)

# ูู ูููุฉ ุชุชุญูู ูู vector ุจุญุฌู 256
# Positional encoding ูุถูู ูุนูููุงุช ุนู ูููุน ุงููููุฉ</code>
                </div>
                <ul>
                    <li><strong>Tokenization:</strong> ูู ูููุฉ ุชุฃุฎุฐ ุฑูู (ID)</li>
                    <li><strong>Embedding:</strong> ุชุญููู ุงูุฑูู ูู vector ุจุญุฌู 256</li>
                    <li><strong>Positional Encoding:</strong> ุฅุถุงูุฉ ูุนูููุงุช ุงูุชุฑุชูุจ</li>
                </ul>
            </div>

            <div class="success-box">
                <h4>ุงููููุฐุฌ ุงูุซุงูู (GPT-2):</h4>
                <p><strong>GPT2 Tokenizer + Pre-trained Embeddings</strong></p>
                <div class="code-block">
                    <code># ุญูุงูู ุงูุณุทุฑ 175-180
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
model = GPT2LMHeadModel.from_pretrained('gpt2')

# ูุณุชุฎุฏู BPE (Byte Pair Encoding)
# Embeddings ูุฏุฑุจุฉ ูุณุจูุงู ุนูู ุจูุงูุงุช ุถุฎูุฉ</code>
                </div>
                <ul>
                    <li><strong>Subword Tokenization:</strong> ุชูุณูู ุฐูู ูููููุงุช</li>
                    <li><strong>Pre-trained Embeddings:</strong> embeddings ุฌุงูุฒุฉ ููููุฉ</li>
                    <li><strong>Contextual:</strong> ูู ูููุฉ ููุง vector ูุฎุชูู ุญุณุจ ุงูุณูุงู</li>
                </ul>
            </div>

            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>ุงูุทุฑููุฉ</th>
                        <th>ูู ุงุณุชุฎุฏููุงูุงุ</th>
                        <th>ุงููููุน ูู ุงูููุฏ</th>
                        <th>ุงูุณุจุจ</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Bag of Words</td>
                        <td>โ ูุง</td>
                        <td>-</td>
                        <td>ูุง ุชุญูุธ ุงูุชุฑุชูุจ ูุงูุณูุงู</td>
                    </tr>
                    <tr>
                        <td>TF-IDF</td>
                        <td>โ ูุง</td>
                        <td>-</td>
                        <td>ููู Classification ููุท</td>
                    </tr>
                    <tr>
                        <td>Word Embeddings</td>
                        <td>โ ูุนู (ุงููููุฐุฌ 1)</td>
                        <td>Embedding Layer</td>
                        <td>ุชูุซูู ุฏูุงูู ูููููุงุช</td>
                    </tr>
                    <tr>
                        <td>Subword Tokens</td>
                        <td>โ ูุนู (ุงููููุฐุฌ 2)</td>
                        <td>GPT2Tokenizer</td>
                        <td>ุชุนุงูู ุฃูุถู ูุน ุงููููุงุช</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <!-- ุงูููุงุฑูุฉ ุจูู ุงููููุฐุฌูู -->
        <section class="section" id="models">
            <h2>โ๏ธ ุงูููุงุฑูุฉ ุงูุดุงููุฉ ุจูู ุงููููุฐุฌูู</h2>

            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>ุงููุนูุงุฑ</th>
                        <th>ุงููููุฐุฌ ุงูุฃูู (Transformer)</th>
                        <th>ุงููููุฐุฌ ุงูุซุงูู (GPT-2)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>ููุน ุงููููุฐุฌ</strong></td>
                        <td>Transformer ูุจูู ูู ุงูุตูุฑ</td>
                        <td>Fine-tuning ุนูู GPT-2</td>
                    </tr>
                    <tr>
                        <td><strong>ุนุฏุฏ Parameters</strong></td>
                        <td>~5-10M parameters</td>
                        <td>117M parameters (GPT-2 small)</td>
                    </tr>
                    <tr>
                        <td><strong>Tokenizer</strong></td>
                        <td>Keras Tokenizer (Word-level)</td>
                        <td>GPT2Tokenizer (Subword BPE)</td>
                    </tr>
                    <tr>
                        <td><strong>Vocab Size</strong></td>
                        <td>~20,000 ูููุฉ</td>
                        <td>50,257 token</td>
                    </tr>
                    <tr>
                        <td><strong>Training ูู ุงูุตูุฑุ</strong></td>
                        <td>โ ูุนู</td>
                        <td>โ ูุง (Fine-tuning ููุท)</td>
                    </tr>
                    <tr>
                        <td><strong>ุนุฏุฏ Epochs</strong></td>
                        <td>5 epochs</td>
                        <td>3 epochs</td>
                    </tr>
                    <tr>
                        <td><strong>Batch Size</strong></td>
                        <td>64</td>
                        <td>4</td>
                    </tr>
                    <tr>
                        <td><strong>Learning Rate</strong></td>
                        <td>Custom schedule ูุน warmup</td>
                        <td>5e-5 (ุซุงุจุช)</td>
                    </tr>
                    <tr>
                        <td><strong>ุฌูุฏุฉ ุงููุชุงุฆุฌ</strong></td>
                        <td>โ๏ธ ููุงู ุนุดูุงุฆู ูุบูุฑ ููููู</td>
                        <td>โ ุฌูุฏุฉ ูููุทููุฉ ูุณุจูุงู</td>
                    </tr>
                    <tr>
                        <td><strong>ููุช ุงูุชุฏุฑูุจ</strong></td>
                        <td>~2600 ุซุงููุฉ (43 ุฏูููุฉ)</td>
                        <td>ูุชุบูุฑ ุญุณุจ ุงูููุงุฑุฏ</td>
                    </tr>
                    <tr>
                        <td><strong>ุงููุฒุงูุง</strong></td>
                        <td>
                            โข ููู ุจููุฉ Transformer<br>
                            โข ุชุญูู ูุงูู ูู Architecture<br>
                            โข ุชุนูููู
                        </td>
                        <td>
                            โข ูุชุงุฆุฌ ุฃูุถู ุจูุซูุฑ<br>
                            โข ูุนุฑูุฉ ูุบููุฉ ูุณุจูุฉ<br>
                            โข ููุงุกุฉ ุฃุนูู
                        </td>
                    </tr>
                    <tr>
                        <td><strong>ุงูุนููุจ</strong></td>
                        <td>
                            โข ูุญุชุงุฌ ุจูุงูุงุช ูููุช ุฃูุซุฑ<br>
                            โข ูุชุงุฆุฌ ุถุนููุฉ<br>
                            โข Overfitting ูุญุชูู
                        </td>
                        <td>
                            โข ุญุฌู ุงููููุฐุฌ ูุจูุฑ<br>
                            โข ูุญุชุงุฌ GPU ูููุฉ<br>
                            โข ุฃูู ูุฑููุฉ
                        </td>
                    </tr>
                </tbody>
            </table>

            <div class="success-box">
                <h3>๐ฏ ุงูุฎูุงุตุฉ</h3>
                <p><strong>ููุงุฐุง ูุงู ุงููููุฐุฌ ุงูุซุงูู ุฃูุถูุ</strong></p>
                <ul>
                    <li>ุงุณุชูุงุฏ ูู ุงููุนุฑูุฉ ุงููุบููุฉ ุงูุถุฎูุฉ ูู GPT-2</li>
                    <li>Tokenizer ุฃุฐูู ูุชุนุงูู ูุน ุงููููุงุช ุจุดูู ุฃูุถู</li>
                    <li>ูููุฐุฌ ุฃูุจุฑ ุจูุซูุฑ (117M vs 5M parameters)</li>
                    <li>Fine-tuning ุฃุณุฑุน ูุฃูุซุฑ ููุงุกุฉ ูู ุงูุชุฏุฑูุจ ูู ุงูุตูุฑ</li>
                </ul>
            </div>

            <div class="info-box">
                <h3>๐ ูุซุงู ุนูู ุงููุชุงุฆุฌ</h3>
                <p><strong>ุงูุณุคุงู:</strong> "Tell me about yourself"</p>

                <p><strong>ุงููููุฐุฌ ุงูุฃูู:</strong></p>
                <div class="code-block">
                    <code>"all buzz ny wind for my friend 1 three recidivist 
1948 gown introduced speeding darryl feelings..."</code>
                </div>
                <span class="badge badge-warning">โ ููุงู ุนุดูุงุฆู ูุบูุฑ ููููู</span>

                <p style="margin-top: 1rem;"><strong>ุงููููุฐุฌ ุงูุซุงูู (ุชูุฑูุจู):</strong></p>
                <div class="code-block">
                    <code>"I'm just a regular person who loves movies and 
talking about them. What would you like to know?"</code>
                </div>
                <span class="badge badge-success">โ ููุทูู ูููููู</span>
            </div>
        </section>

        <!-- ุงูููุงููู ุงูุฃุณุงุณูุฉ -->
        <section class="section" id="concepts">
            <h2>๐ ููุงููู ุฃุณุงุณูุฉ ุฅุถุงููุฉ</h2>

            <h3>1๏ธโฃ Fine-tuning vs Training from Scratch</h3>
            <div class="info-box">
                <h4>Training from Scratch (ุงููููุฐุฌ ุงูุฃูู):</h4>
                <ul>
                    <li>ุงูุจุฏุงูุฉ ูู ุงูุตูุฑ ุชูุงูุงู</li>
                    <li>ุชุนูู ูู ุดูุก ูู ุงูุจูุงูุงุช ุงููุชุงุญุฉ ููุท</li>
                    <li>ูุญุชุงุฌ ุจูุงูุงุช ุถุฎูุฉ (ููุงููู ุงูุนููุงุช)</li>
                    <li>ููุช ูููุงุฑุฏ ูุซูุฑุฉ ุฌุฏุงู</li>
                </ul>

                <h4>Fine-tuning (ุงููููุฐุฌ ุงูุซุงูู):</h4>
                <ul>
                    <li>ุงูุจุฏุงูุฉ ูู ูููุฐุฌ ูุฏุฑุจ ูุณุจูุงู</li>
                    <li>ุชุนุฏูู ุจุณูุท ููุชููู ูุน ุงููููุฉ ุงูุฌุฏูุฏุฉ</li>
                    <li>ูุญุชุงุฌ ุจูุงูุงุช ุฃูู ุจูุซูุฑ</li>
                    <li>ุฃุณุฑุน ูุฃูุซุฑ ููุงุกุฉ</li>
                </ul>
            </div>

            <h3>2๏ธโฃ Attention Mechanism</h3>
            <div class="code-block">
                <code># ููุฌูุฏ ูู ุงููููุฐุฌ ุงูุฃูู - ุญูุงูู ุงูุณุทุฑ 280-300
MultiHeadAttention(num_heads=8, key_dim=d_model)

# ูุณูุญ ูููููุฐุฌ ุจุงูุชุฑููุฒ ุนูู ุฃุฌุฒุงุก ูุฎุชููุฉ ูู ุงูุฌููุฉ
# ูุซุงู: ูู "The cat sat on the mat"
# ุนูุฏ ูุนุงูุฌุฉ "sat"ุ ุงููููุฐุฌ ููุชุจู ูู "cat" ู "mat"</code>
            </div>

            <h3>3๏ธโฃ Label Smoothing</h3>
            <div class="code-block">
                <code># ูู ุงููููุฐุฌ ุงูุฃูู - ุงูุณุทุฑ 410-420
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(
    from_logits=True,
    label_smoothing=0.1
)

# ุจุฏูุงู ูู: [0, 0, 1, 0, 0] (One-hot)
# ูุตุจุญ: [0.02, 0.02, 0.92, 0.02, 0.02]
# ูููุน ุงูู Overconfidence</code>
            </div>

            <h3>4๏ธโฃ Gradient Clipping</h3>
            <div class="code-block">
                <code># ูู ุงููููุฐุฌ ุงูุฃูู - ุงูุณุทุฑ 450-470
grads, _ = tf.clip_by_global_norm(gradients, 1.0)

# ูููุน ุงูู gradients ูู ุงูุงููุฌุงุฑ (Exploding Gradients)
# ููู ููุงุณุชูุฑุงุฑ ูู ุงูุชุฏุฑูุจ</code>
            </div>

            <h3>5๏ธโฃ Learning Rate Schedule</h3>
            <div class="code-block">
                <code># ูู ุงููููุฐุฌ ุงูุฃูู - ุงูุณุทุฑ 430-445
class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):
    def __call__(self, step):
        # Warmup ููู 4000 ุฎุทูุฉ ุงูุฃููู
        # ุซู ุชูุงูุต ุชุฏุฑูุฌู

# ูุณุงุนุฏ ูู ุงูุชุฏุฑูุจ ุงูุฃูุถู ูุงูุฃุณุฑุน</code>
            </div>
        </section>

        <!-- ููุชุจุฉ TextBlob -->
        <section class="section" id="textblob">
            <h2>๐ ููุชุจุฉ TextBlob</h2>

            <div class="info-box">
                <h3>ูุง ูู TextBlobุ</h3>
                <p>ููุชุจุฉ Python ุจุณูุทุฉ ููููุฉ ููุนุงูุฌุฉ ุงูุจูุงูุงุช ุงููุตูุฉ (NLP)</p>
            </div>

            <h3>ุงููููุฒุงุช ุงูุฑุฆูุณูุฉ:</h3>

            <h4>1๏ธโฃ ุณูููุฉ ุงูุงุณุชุฎุฏุงู</h4>
            <div class="code-block">
                <code>from textblob import TextBlob

text = TextBlob("I love machine learning")
print(text.words)  # ['I', 'love', 'machine', 'learning']
print(text.tags)   # [('I', 'PRP'), ('love', 'VBP'), ...]</code>
            </div>

            <h4>2๏ธโฃ Sentiment Analysis (ุชุญููู ุงููุดุงุนุฑ)</h4>
            <div class="code-block">
                <code>text = TextBlob("This movie is amazing!")
print(text.sentiment)
# Sentiment(polarity=0.8, subjectivity=0.9)
# polarity: ูู -1 (ุณูุจู) ุฅูู 1 (ุฅูุฌุงุจู)
# subjectivity: ูู 0 (ููุถูุนู) ุฅูู 1 (ุฐุงุชู)</code>
            </div>

            <h4>3๏ธโฃ Spelling Correction</h4>
            <div class="code-block">
                <code>text = TextBlob("I havv goood speling")
print(text.correct())
# "I have good spelling"</code>
            </div>

            <h4>4๏ธโฃ POS Tagging</h4>
            <div class="code-block">
                <code>text = TextBlob("Python is awesome")
print(text.tags)
# [('Python', 'NNP'), ('is', 'VBZ'), ('awesome', 'JJ')]</code>
            </div>

            <h4>5๏ธโฃ Noun Phrase Extraction</h4>
            <div class="code-block">
                <code>text = TextBlob("The big brown dog jumped")
print(text.noun_phrases)
# ['big brown dog']</code>
            </div>

            <h4>6๏ธโฃ Translation & Language Detection</h4>
            <div class="code-block">
                <code>text = TextBlob("Hello World")
print(text.translate(to="es"))  # "Hola Mundo"
print(text.detect_language())   # 'en'</code>
            </div>

            <h4>7๏ธโฃ Lemmatization</h4>
            <div class="code-block">
                <code>from textblob import Word

word = Word("running")
print(word.lemmatize("v"))  # 'run'

word = Word("better")
print(word.lemmatize("a"))  # 'good'</code>
            </div>

            <div class="success-box">
                <h3>๐ฏ ุฃูููุฉ TextBlob</h3>
                <ul>
                    <li><strong>ุณููุฉ ุงูุชุนูู:</strong> API ุจุณูุทุฉ ููุงุถุญุฉ ูููุจุชุฏุฆูู</li>
                    <li><strong>ูุชุนุฏุฏุฉ ุงููุธุงุฆู:</strong> ุชุบุทู ูุนุธู ููุงู NLP ุงูุฃุณุงุณูุฉ</li>
                    <li><strong>ููุงุณุจุฉ ููู Prototyping:</strong> ุงุฎุชุจุงุฑ ุงูุฃููุงุฑ ุจุณุฑุนุฉ</li>
                    <li><strong>Built on NLTK:</strong> ุชุณุชุฎุฏู ููุชุจุฉ NLTK ุงููููุฉ ูู ุงูุฎูููุฉ</li>
                    <li><strong>ุฏุนู ูุชุนุฏุฏ ุงููุบุงุช:</strong> ุชุฑุฌูุฉ ูุชุญููู ูุบุงุช ูุฎุชููุฉ</li>
                </ul>
            </div>

            <div class="warning-box">
                <h3>โ๏ธ ูุชู ูุง ูุณุชุฎุฏู TextBlobุ</h3>
                <ul>
                    <li>ุงููุดุงุฑูุน ุงููุจูุฑุฉ ุงูุชู ุชุญุชุงุฌ ุฃุฏุงุก ุนุงูู (ุงุณุชุฎุฏู SpaCy)</li>
                    <li>ุงูุชุทุจููุงุช ุงูุฅูุชุงุฌูุฉ ุงูุชู ุชุญุชุงุฌ ุณุฑุนุฉ (ุงุณุชุฎุฏู ููุชุจุงุช ูุฎุตุตุฉ)</li>
                    <li>ููุงู NLP ูุนูุฏุฉ ุฌุฏุงู (ุงุณุชุฎุฏู Transformers)</li>
                </ul>
            </div>

            <div class="info-box">
                <h3>๐ ููุงุฑูุฉ ูุน ููุชุจุงุช ุฃุฎุฑู</h3>
                <table class="comparison-table">
                    <thead>
                        <tr>
                            <th>ุงูููุชุจุฉ</th>
                            <th>ุงูุฃูุถู ูู</th>
                            <th>ุงูุณุฑุนุฉ</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>TextBlob</td>
                            <td>ุงููุจุชุฏุฆูู ูุงูู Prototyping</td>
                            <td>ุจุทูุฆุฉ</td>
                        </tr>
                        <tr>
                            <td>SpaCy</td>
                            <td>ุงูุฅูุชุงุฌ ูุงูุชุทุจููุงุช ุงููุจูุฑุฉ</td>
                            <td>ุณุฑูุนุฉ ุฌุฏุงู</td>
                        </tr>
                        <tr>
                            <td>NLTK</td>
                            <td>ุงูุจุญุซ ุงูุฃูุงุฏููู ูุงูุชุนููู</td>
                            <td>ูุชูุณุทุฉ</td>
                        </tr>
                        <tr>
                            <td>Transformers</td>
                            <td>ููุงู NLP ุงููุชูุฏูุฉ</td>
                            <td>ุชุนุชูุฏ ุนูู GPU</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </section>

        <!-- ุงูุฎูุงุตุฉ ุงูููุงุฆูุฉ -->
        <section class="section">
            <h2>๐ ุงูุฎูุงุตุฉ ุงูููุงุฆูุฉ</h2>

            <div class="success-box">
                <h3>โ ูุง ุชุนูููุงู ูู ุงููุดุฑูุน:</h3>
                <ol>
                    <li><strong>Fine-tuning ุฃูุถู ูู ุงูุชุฏุฑูุจ ูู ุงูุตูุฑ</strong> ุนูุฏูุง ุชููู ุงูุจูุงูุงุช ูุญุฏูุฏุฉ</li>
                    <li><strong>ุงูููุงุฐุฌ ุงููุฏุฑุจุฉ ูุณุจูุงู</strong> ุชุญุชูู ุนูู ูุนุฑูุฉ ูุบููุฉ ูููุฉ</li>
                    <li><strong>ุฌูุฏุฉ ุงูู Tokenizer</strong> ุชุคุซุฑ ุจุดูู ูุจูุฑ ุนูู ุงููุชุงุฆุฌ</li>
                    <li><strong>Subword Tokenization</strong> ุฃูุถู ูู Word-level ููููุงุฐุฌ ุงูุญุฏูุซุฉ</li>
                    <li><strong>Text Generation ุตุนุจ</strong> ููุญุชุงุฌ ุจูุงูุงุช ุถุฎูุฉ ููุชุฏุฑูุจ ูู ุงูุตูุฑ</li>
                </ol>
            </div>

            <div class="info-box">
                <h3>๐ ุงูุชุญุณููุงุช ุงูููููุฉ:</h3>
                <ul>
                    <li>ุงุณุชุฎุฏุงู ููุงุฐุฌ ุฃูุจุฑ (GPT-2 Medium ุฃู Large)</li>
                    <li>ุฒูุงุฏุฉ ุนุฏุฏ ุงูู Training samples</li>
                    <li>ุชุทุจูู Data Augmentation</li>
                    <li>ุงุณุชุฎุฏุงู Beam Search ุจุฏูุงู ูู Sampling</li>
                    <li>ุฅุถุงูุฉ Conversation History ููุณูุงู</li>
                </ul>
            </div>

            <div class="warning-box">
                <h3>โ๏ธ ุงูููุงุท ุงููููุฉ ููููุงูุดุฉ:</h3>
                <ul>
                    <li>ููุงุฐุง ูุดู ุงููููุฐุฌ ุงูุฃูู ูููู ูููู ุชุญุณููู</li>
                    <li>ุงููุฑู ุจูู Encoder-Decoder (Transformer) ู Decoder-only (GPT)</li>
                    <li>ุฃูููุฉ ุงูู Pre-training ูู NLP</li>
                    <li>ููู ูุนูู Attention Mechanism</li>
                    <li>ูุนูู Perplexity ูููู ูููุณ ุฌูุฏุฉ ุงููููุฐุฌ</li>
                </ul>
            </div>
        </section>

        <!-- ูุณู Old Tasks -->
        <section class="section" id="old-tasks">
            <h2>๐ Old Tasks - ุงูููุงู ุงูุณุงุจูุฉ</h2>

            <div class="info-box">
                <p><strong>๐ก ููุญูุธุฉ:</strong> ุงููุณู ุฏุง ููู ุดุฑุญ ุชูุตููู ููููุงู ุงูุณุงุจูุฉ ุงููู ุงุชุนููุช ุนูู ููุชุจุฉ TextBlob</p>
                <p>ุฏุง ูููุฑุงุฌุนุฉ ูุงูููู ุงูุดุงูู ููููุชุจุฉ ูุฅููุงููุงุชูุง</p>
            </div>

            <!-- Task 1: Syntax Features -->
            <h3>๐ค Task 1: Syntax Features in TextBlob</h3>

            <div class="info-box">
                <h4>ูุง ูู ุงูู Syntax Featuresุ</h4>
                <p>ุงูู Syntax Features ูู ูุฌููุนุฉ ูู ุงูุฃุฏูุงุช ูููู <strong>ุงูุชุฑููุจ ุงููุญูู</strong> ูุงูุนูุงูุงุช ุงููุบููุฉ ูู
                    ุงููุต</p>
                <p>ุจุชุณุงุนุฏูุง ูุญูู ุงูุฌูู ููููุงุชูุง ููููู ุฏูุฑ ูู ูููุฉ ูู ุงูุฌููุฉ</p>
            </div>

            <h4>1๏ธโฃ Tokenization (ุงูุชูุณูู)</h4>
            <div class="code-block">
                <code>from textblob import TextBlob

text = "TextBlob is amazing! It helps with NLP tasks."
blob = TextBlob(text)

# ุชูุณูู ูุฌูู
sentences = blob.sentences
print(sentences)
# Output: [Sentence('TextBlob is amazing!'), 
#          Sentence('It helps with NLP tasks.')]

# ุชูุณูู ููููุงุช
words = blob.words
print(words)
# Output: WordList(['TextBlob', 'is', 'amazing', 'It', 
#                   'helps', 'with', 'NLP', 'tasks'])</code>
            </div>

            <div class="success-box">
                <p><strong>๐ก ุงููุงุฆุฏุฉ:</strong></p>
                <ul>
                    <li><strong>blob.sentences:</strong> ููุณู ุงููุต ูุฌูู ูููุตูุฉ</li>
                    <li><strong>blob.words:</strong> ููุณู ุงููุต ููููุงุช (tokens)</li>
                    <li>ุฃุณุงุณู ูุฃู ูุนุงูุฌุฉ ูููุตูุต</li>
                </ul>
            </div>

            <h4>2๏ธโฃ Part-of-Speech (POS) Tagging (ุชุญุฏูุฏ ููุน ุงููููุฉ)</h4>
            <div class="code-block">
                <code>blob = TextBlob("Python is a powerful programming language")

# ุงูุญุตูู ุนูู ุงูู POS tags
tags = blob.tags
print(tags)

# Output:
# [('Python', 'NNP'),      # Proper Noun (ุงุณู ุนูู)
#  ('is', 'VBZ'),           # Verb (ูุนู)
#  ('a', 'DT'),             # Determiner (ุฃุฏุงุฉ)
#  ('powerful', 'JJ'),      # Adjective (ุตูุฉ)
#  ('programming', 'NN'),   # Noun (ุงุณู)
#  ('language', 'NN')]      # Noun (ุงุณู)</code>
            </div>

            <div class="info-box">
                <h4>๐ Penn Treebank Tags ุงูุดุงุฆุนุฉ:</h4>
                <table class="comparison-table">
                    <thead>
                        <tr>
                            <th>Tag</th>
                            <th>ุงููุนูู</th>
                            <th>ูุซุงู</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>NN</strong></td>
                            <td>Noun, singular (ุงุณู ููุฑุฏ)</td>
                            <td>cat, dog, book</td>
                        </tr>
                        <tr>
                            <td><strong>NNS</strong></td>
                            <td>Noun, plural (ุงุณู ุฌูุน)</td>
                            <td>cats, dogs, books</td>
                        </tr>
                        <tr>
                            <td><strong>NNP</strong></td>
                            <td>Proper noun (ุงุณู ุนูู)</td>
                            <td>Python, Egypt, John</td>
                        </tr>
                        <tr>
                            <td><strong>VB</strong></td>
                            <td>Verb, base form (ูุนู ุฃุตูู)</td>
                            <td>run, eat, go</td>
                        </tr>
                        <tr>
                            <td><strong>VBD</strong></td>
                            <td>Verb, past tense (ูุนู ูุงุถู)</td>
                            <td>ran, ate, went</td>
                        </tr>
                        <tr>
                            <td><strong>VBG</strong></td>
                            <td>Verb, gerund (ูุนู ูุณุชูุฑ)</td>
                            <td>running, eating, going</td>
                        </tr>
                        <tr>
                            <td><strong>JJ</strong></td>
                            <td>Adjective (ุตูุฉ)</td>
                            <td>big, beautiful, fast</td>
                        </tr>
                        <tr>
                            <td><strong>RB</strong></td>
                            <td>Adverb (ุธุฑู)</td>
                            <td>quickly, very, well</td>
                        </tr>
                        <tr>
                            <td><strong>DT</strong></td>
                            <td>Determiner (ุฃุฏุงุฉ ุชุนุฑูู)</td>
                            <td>the, a, an</td>
                        </tr>
                        <tr>
                            <td><strong>PRP</strong></td>
                            <td>Personal pronoun (ุถููุฑ)</td>
                            <td>I, you, he, she</td>
                        </tr>
                    </tbody>
                </table>

                <p><strong>๐ก ุงููุงุฆุฏุฉ:</strong> ูุนุฑูุฉ ููุน ูู ูููุฉ ูุณุงุนุฏ ูู:</p>
                <ul>
                    <li>ุงูู Lemmatization ุงูุตุญูุญ (ูู ููุน ูู ุทุฑููุฉ)</li>
                    <li>ููู ุจูุงุก ุงูุฌููุฉ</li>
                    <li>ุงุณุชุฎุฑุงุฌ ูุนูููุงุช ูุญุฏุฏุฉ (ูุซูุงู ูู ุงูุฃูุนุงู ุฃู ุงูุฃุณูุงุก)</li>
                </ul>
            </div>

            <h4>3๏ธโฃ Noun Phrase Extraction (ุงุณุชุฎุฑุงุฌ ุงูุนุจุงุฑุงุช ุงูุงุณููุฉ)</h4>
            <div class="code-block">
                <code>blob = TextBlob("The beautiful garden has many colorful flowers")

noun_phrases = blob.noun_phrases
print(noun_phrases)

# Output: WordList(['beautiful garden', 'colorful flowers'])</code>
            </div>

            <div class="success-box">
                <p><strong>๐ก ุงููุงุฆุฏุฉ:</strong></p>
                <ul>
                    <li>ูุณุชุฎุฑุฌ <strong>ุงูุนุจุงุฑุงุช ุงูุงุณููุฉ</strong> (ูุฌููุนุฉ ูููุงุช ุชุนูู ูุงุณู ูุงุญุฏ)</li>
                    <li>ูููุฏ ุฌุฏุงู ูู <strong>ุงุณุชุฎุฑุงุฌ ุงูููุงููู ุงูุฑุฆูุณูุฉ</strong></li>
                    <li>ุฃูุถู ูู ุงุณุชุฎุฑุงุฌ ุงููููุงุช ุงูููุฑุฏุฉ</li>
                </ul>
            </div>

            <h4>4๏ธโฃ Word Inflection & Lemmatization (ุงูุชุตุฑูู ูุงูุชุฌุฐูุฑ)</h4>
            <div class="code-block">
                <code>from textblob import Word

# Singularize (ุชุญููู ููููุฑุฏ)
word = Word("cats")
print(word.singularize())  # Output: cat

word = Word("children")
print(word.singularize())  # Output: child

# Pluralize (ุชุญููู ููุฌูุน)
word = Word("cat")
print(word.pluralize())  # Output: cats

# Lemmatization (ุงูุชุฌุฐูุฑ)
word = Word("running")
print(word.lemmatize("v"))  # Output: run (v = verb)

word = Word("better")
print(word.lemmatize("a"))  # Output: good (a = adjective)</code>
            </div>

            <div class="warning-box">
                <p><strong>โ๏ธ ููุญูุธุฉ ูููุฉ:</strong></p>
                <p>ุงูู Lemmatization ูุญุชุงุฌ ูุนุฑูุฉ ููุน ุงููููุฉ (POS tag) ููุชูุฌุฉ ุตุญูุญุฉ:</p>
                <ul>
                    <li><code>lemmatize("v")</code> ููุฃูุนุงู (verbs)</li>
                    <li><code>lemmatize("n")</code> ููุฃุณูุงุก (nouns) - default</li>
                    <li><code>lemmatize("a")</code> ููุตูุงุช (adjectives)</li>
                    <li><code>lemmatize("r")</code> ููุธุฑูู (adverbs)</li>
                </ul>
            </div>

            <h4>5๏ธโฃ Sentence Parsing (ุชุญููู ุจููุฉ ุงูุฌููุฉ)</h4>
            <div class="code-block">
                <code>blob = TextBlob("The cat sat on the mat")

# ุนุฑุถ ุงูู parse tree
print(blob.parse())

# Output:
# (S
#   (NP The/DT cat/NN)
#   (VP sat/VBD
#     (PP on/IN
#       (NP the/DT mat/NN))))</code>
            </div>

            <div class="info-box">
                <p><strong>๐ก ุงููุงุฆุฏุฉ:</strong></p>
                <ul>
                    <li>ูุนุฑุถ <strong>ุดุฌุฑุฉ ุงูุชุญููู ุงููุญูู</strong> (Parse Tree)</li>
                    <li>ููุถุญ ุงูุนูุงูุงุช ุจูู ุงููููุงุช</li>
                    <li>NP = Noun Phrase, VP = Verb Phrase, PP = Prepositional Phrase</li>
                </ul>
            </div>

            <h4>6๏ธโฃ Word Count & Frequency (ุนุฏ ุงููููุงุช ูุชูุฑุงุฑูุง)</h4>
            <div class="code-block">
                <code>from collections import Counter

blob = TextBlob("the cat and the dog and the bird")

# ุนุฏ ุชูุฑุงุฑ ุงููููุงุช
word_freq = Counter(blob.words)
print(word_freq)

# Output: Counter({'the': 3, 'and': 2, 'cat': 1, 'dog': 1, 'bird': 1})

# ุฃูุซุฑ 3 ูููุงุช ุชูุฑุงุฑุงู
print(word_freq.most_common(3))
# Output: [('the', 3), ('and', 2), ('cat', 1)]</code>
            </div>

            <h4>7๏ธโฃ Word and Sentence Properties (ุฎุตุงุฆุต ุงููุต)</h4>
            <div class="code-block">
                <code>blob = TextBlob("I love Python. Python is great for data science.")

# ุนุฏุฏ ุงูุฌูู
num_sentences = len(blob.sentences)
print(f"Number of sentences: {num_sentences}")  # Output: 2

# ุนุฏุฏ ุงููููุงุช
num_words = len(blob.words)
print(f"Number of words: {num_words}")  # Output: 10

# ูุชูุณุท ุทูู ุงูุฌููุฉ
avg_length = num_words / num_sentences
print(f"Average sentence length: {avg_length:.2f} words")  # Output: 5.00</code>
            </div>

            <!-- Task 2: Morphology -->
            <h3>๐ฌ Task 2: Morphology in TextBlob</h3>

            <div class="info-box">
                <h4>ูุง ูู Morphology (ุนูู ุงูุตุฑู)ุ</h4>
                <p><strong>Morphology</strong> ูู ุฏุฑุงุณุฉ <strong>ุจููุฉ ูุชูููู ุงููููุงุช</strong></p>
                <p>ูู TextBlobุ ุจูุชุนุงูู ูุน Morphology ูู ุฎูุงู:</p>
                <ul>
                    <li><strong>Lemmatization:</strong> ุฅุฑุฌุงุน ุงููููุฉ ูุฃุตููุง ูู ุงููุงููุณ</li>
                    <li><strong>Stemming:</strong> ูุต ุงููููุฉ ูุฌุฐุฑูุง (ุจุฏูู ุงุณุชุฎุฏุงู ูุงููุณ)</li>
                </ul>
            </div>

            <h4>๐ Flowchart ููุชุญููู ุงูุตุฑูู:</h4>
            <div class="code-block">
                <code>1. Raw Text Input
   โ
2. Word Tokenization (ุชูุณูู ููููุงุช)
   โ
3. POS Tagging (ุชุญุฏูุฏ ููุน ุงููููุฉ)
   โ
4. Lemmatization / Stemming (ุงูุชุฌุฐูุฑ)
   โ
5. Processed Text Output</code>
            </div>

            <h4>๐ ูุซุงู ุนููู ูุงูู:</h4>
            <div class="code-block">
                <code>from textblob import TextBlob, Word

# 1. Raw Text
text = "The cats were running quickly towards the mice"
blob = TextBlob(text)

# 2. Tokenization
words = blob.words
print("Words:", words)
# Output: ['The', 'cats', 'were', 'running', 'quickly', 'towards', 'the', 'mice']

# 3. POS Tagging
tags = blob.tags
print("\nPOS Tags:", tags)
# Output: [('The', 'DT'), ('cats', 'NNS'), ('were', 'VBD'), 
#          ('running', 'VBG'), ('quickly', 'RB'), ...]

# 4. Lemmatization based on POS
lemmatized = []
for word, pos in blob.tags:
    word_obj = Word(word.lower())
    
    # ุชุญุฏูุฏ ููุน ุงููููุฉ ููู lemmatization
    if pos.startswith('V'):  # Verb
        lemma = word_obj.lemmatize('v')
    elif pos.startswith('N'):  # Noun
        lemma = word_obj.lemmatize('n')
    elif pos.startswith('J'):  # Adjective
        lemma = word_obj.lemmatize('a')
    elif pos.startswith('R'):  # Adverb
        lemma = word_obj.lemmatize('r')
    else:
        lemma = word_obj.lemmatize()
    
    lemmatized.append(lemma)

print("\nLemmatized:", lemmatized)
# Output: ['the', 'cat', 'be', 'run', 'quickly', 'towards', 'the', 'mouse']

# 5. Processed Text
processed_text = ' '.join(lemmatized)
print("\nProcessed:", processed_text)
# Output: the cat be run quickly towards the mouse</code>
            </div>

            <div class="success-box">
                <h4>๐ Lemmatization vs Stemming:</h4>
                <table class="comparison-table">
                    <thead>
                        <tr>
                            <th>ุงูููุฒุฉ</th>
                            <th>Lemmatization</th>
                            <th>Stemming</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>ุงูุชุนุฑูู</strong></td>
                            <td>ุฅุฑุฌุงุน ุงููููุฉ ูุฃุตููุง ูู ุงููุงููุณ</td>
                            <td>ูุต ุงููููุฉ ูุฌุฐุฑูุง ุงูุฃุณุงุณู</td>
                        </tr>
                        <tr>
                            <td><strong>ูุณุชุฎุฏู ูุงููุณุ</strong></td>
                            <td>โ ูุนู (WordNet)</td>
                            <td>โ ูุง</td>
                        </tr>
                        <tr>
                            <td><strong>ูุญุชุงุฌ POSุ</strong></td>
                            <td>โ ูุนู (ููุฏูุฉ)</td>
                            <td>โ ูุง</td>
                        </tr>
                        <tr>
                            <td><strong>ุงููุชูุฌุฉ</strong></td>
                            <td>ูููุฉ ุตุญูุญุฉ ูู ุงููุงููุณ</td>
                            <td>ูุฏ ูุง ุชููู ูููุฉ ุญููููุฉ</td>
                        </tr>
                        <tr>
                            <td><strong>ุงูุณุฑุนุฉ</strong></td>
                            <td>โ๏ธ ุฃุจุทุฃ</td>
                            <td>โ ุฃุณุฑุน</td>
                        </tr>
                        <tr>
                            <td><strong>ุงูุฏูุฉ</strong></td>
                            <td>โ ุฃุนูู</td>
                            <td>โ๏ธ ุฃูู</td>
                        </tr>
                        <tr>
                            <td><strong>ูุซุงู</strong></td>
                            <td>running โ run<br>better โ good</td>
                            <td>running โ run<br>better โ better</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="warning-box">
                <p><strong>โ๏ธ ููุญูุธุฉ:</strong> TextBlob ูุง ูููุฑ Stemming ูุจุงุดุฑุฉุ ููู ูููู ุงุณุชุฎุฏุงูู ูู ุฎูุงู NLTK:</p>
                <div class="code-block">
                    <code>from nltk.stem import PorterStemmer

stemmer = PorterStemmer()
word = "running"
stem = stemmer.stem(word)
print(stem)  # Output: run</code>
                </div>
            </div>

            <!-- Task 3: Vectorization -->
            <h3>๐ข Task 3: Vectorization using TextBlob</h3>

            <div class="info-box">
                <h4>ูุง ูู Vectorizationุ</h4>
                <p><strong>Vectorization</strong> ูู ุชุญููู ุงููุตูุต ุฅูู <strong>ุฃุฑูุงู (vectors)</strong> ููู ุชููููุง ููุงุฐุฌ
                    ุงูู Machine Learning</p>
                <p>ุงููุตูุต ูุงุฒู ุชุชุญูู ูุฃุฑูุงู ูุฃู ุงูู algorithms ูุด ุจุชููู ูููุงุช!</p>
            </div>

            <h4>๐ ุฃููุงุน Vectorization:</h4>

            <h5>1๏ธโฃ Count Vectorization (Bag of Words)</h5>
            <div class="code-block">
                <code>from sklearn.feature_extraction.text import CountVectorizer
from textblob import TextBlob

# ูุนุงูุฌุฉ ุงููุตูุต ุจุงุณุชุฎุฏุงู TextBlob
texts = [
    "I love machine learning",
    "I love deep learning",
    "Machine learning is amazing"
]

# Preprocessing with TextBlob
processed_texts = []
for text in texts:
    blob = TextBlob(text.lower())
    # Lemmatization
    words = [Word(word).lemmatize() for word in blob.words]
    processed_texts.append(' '.join(words))

print("Processed texts:", processed_texts)
# Output: ['i love machine learning', 
#          'i love deep learning', 
#          'machine learning be amazing']

# Count Vectorization
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(processed_texts)

print("\nVocabulary:", vectorizer.get_feature_names_out())
# Output: ['amazing', 'be', 'deep', 'i', 'learning', 'love', 'machine']

print("\nCount Matrix:")
print(X.toarray())
# Output:
# [[0 0 0 1 1 1 1]   # Doc 1: "i love machine learning"
#  [0 0 1 1 1 1 0]   # Doc 2: "i love deep learning"
#  [1 1 0 0 1 0 1]]  # Doc 3: "machine learning is amazing"</code>
            </div>

            <div class="info-box">
                <p><strong>๐ก ููู ูุนูู Count Vectorizationุ</strong></p>
                <ol>
                    <li>ููุดุฆ <strong>ููุฑุฏุงุช (vocabulary)</strong> ูู ูู ุงููููุงุช ุงููุฑูุฏุฉ</li>
                    <li>ูู document ูุตุจุญ vector ููู ุนุฏุฏ ุชูุฑุงุฑ ูู ูููุฉ</li>
                    <li>ุงูุตูุฑ ูุนูู ุงููููุฉ ุบูุฑ ููุฌูุฏุฉ</li>
                </ol>

                <p><strong>โ๏ธ ุงููุดููุฉ:</strong> ุงููููุงุช ุงูุดุงุฆุนุฉ (the, is, a) ุชุญุตู ุนูู weights ุนุงููุฉ!</p>
            </div>

            <h5>2๏ธโฃ TF-IDF Vectorization</h5>
            <div class="code-block">
                <code>from sklearn.feature_extraction.text import TfidfVectorizer

# ููุณ ุงููุตูุต ุงููุนุงูุฌุฉ
tfidf_vectorizer = TfidfVectorizer()
X_tfidf = tfidf_vectorizer.fit_transform(processed_texts)

print("TF-IDF Matrix:")
print(X_tfidf.toarray())

# Output (ูุซุงู):
# [[0.00 0.00 0.00 0.50 0.40 0.50 0.50]
#  [0.00 0.00 0.63 0.38 0.30 0.38 0.00]
#  [0.57 0.57 0.00 0.00 0.34 0.00 0.57]]</code>
            </div>

            <div class="success-box">
                <h4>๐ TF-IDF Formulas:</h4>

                <p><strong>TF (Term Frequency):</strong></p>
                <div class="code-block">
                    <code>TF = (ุนุฏุฏ ูุฑุงุช ุธููุฑ ุงููููุฉ ูู ุงููุณุชูุฏ) / (ุฅุฌูุงูู ูููุงุช ุงููุณุชูุฏ)</code>
                </div>

                <p><strong>IDF (Inverse Document Frequency):</strong></p>
                <div class="code-block">
                    <code>IDF = log(ุฅุฌูุงูู ุนุฏุฏ ุงููุณุชูุฏุงุช / ุนุฏุฏ ุงููุณุชูุฏุงุช ุงูุชู ุชุญุชูู ุงููููุฉ)</code>
                </div>

                <p><strong>TF-IDF:</strong></p>
                <div class="code-block">
                    <code>TF-IDF = TF ร IDF</code>
                </div>

                <p><strong>๐ก ุงูููุฑุฉ:</strong></p>
                <ul>
                    <li>ุงููููุงุช <strong>ุงูุดุงุฆุนุฉ</strong> (the, is) ุชุญุตู ุนูู <strong>IDF ููุฎูุถ</strong></li>
                    <li>ุงููููุงุช <strong>ุงููุงุฏุฑุฉ ูุงููููุฉ</strong> ุชุญุตู ุนูู <strong>IDF ุนุงูู</strong></li>
                    <li>ุงููุชูุฌุฉ: weights ุฃูุถู ุชุนูุณ ุฃูููุฉ ุงููููุฉ!</li>
                </ul>
            </div>

            <h4>๐ Complete Vectorization Pipeline:</h4>
            <div class="code-block">
                <code>from textblob import TextBlob, Word
from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd

# ูุซุงู ูุงูู
documents = [
    "TextBlob is simple and powerful",
    "I love using TextBlob for NLP",
    "TextBlob makes NLP tasks easy"
]

# Step 1: Preprocessing
def preprocess(text):
    blob = TextBlob(text.lower())
    
    # Tokenization + Lemmatization + POS-aware
    processed_words = []
    for word, pos in blob.tags:
        word_obj = Word(word)
        
        if pos.startswith('V'):
            lemma = word_obj.lemmatize('v')
        elif pos.startswith('N'):
            lemma = word_obj.lemmatize('n')
        else:
            lemma = word_obj.lemmatize()
        
        processed_words.append(lemma)
    
    return ' '.join(processed_words)

# ุชุทุจูู Preprocessing
processed_docs = [preprocess(doc) for doc in documents]
print("Processed Documents:")
for i, doc in enumerate(processed_docs, 1):
    print(f"{i}. {doc}")

# Step 2: TF-IDF Vectorization
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(processed_docs)

# Step 3: ุนุฑุถ ุงููุชุงุฆุฌ
feature_names = vectorizer.get_feature_names_out()
df = pd.DataFrame(
    tfidf_matrix.toarray(),
    columns=feature_names,
    index=[f'Doc{i+1}' for i in range(len(documents))]
)

print("\nTF-IDF Matrix:")
print(df.round(3))</code>
            </div>

            <h4>๐ ููุงุฑูุฉ ุทุฑู Vectorization:</h4>
            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>ุงูุทุฑููุฉ</th>
                        <th>ุงูููุฑุฉ</th>
                        <th>ุงููููุฒุงุช</th>
                        <th>ุงูุนููุจ</th>
                        <th>ุงูุงุณุชุฎุฏุงู</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Bag of Words (Count)</strong></td>
                        <td>ุนุฏ ุชูุฑุงุฑ ุงููููุงุช</td>
                        <td>โข ุจุณูุท<br>โข ุณุฑูุน<br>โข ุณูู ุงูููู</td>
                        <td>โข ูุชุฌุงูู ุงูุชุฑุชูุจ<br>โข ูุชุฌุงูู ุงูุณูุงู<br>โข Stop words ุนุงููุฉ</td>
                        <td>Classification ุจุณูุท</td>
                    </tr>
                    <tr>
                        <td><strong>TF-IDF</strong></td>
                        <td>ูุฒู ุญุณุจ ุงูุฃูููุฉ</td>
                        <td>โข ูููู Stop words<br>โข ูุจุฑุฒ ูููุงุช ูููุฉ<br>โข ุฃูุถู ูู Count</td>
                        <td>โข ูุชุฌุงูู ุงูุชุฑุชูุจ<br>โข ูุชุฌุงูู ุงูุณูุงู<br>โข Sparse matrix</td>
                        <td>Information Retrieval<br>Document Classification</td>
                    </tr>
                    <tr>
                        <td><strong>Word Embeddings</strong></td>
                        <td>Dense vectors ุจุณูุงู</td>
                        <td>โข ูุญูุธ ุงูุณูุงู<br>โข ูููู ุงูุชุดุงุจู<br>โข Dense vectors</td>
                        <td>โข ูุนูุฏ<br>โข ูุญุชุงุฌ ุชุฏุฑูุจ<br>โข ุฃุจุทุฃ</td>
                        <td>Deep Learning<br>Semantic Tasks</td>
                    </tr>
                </tbody>
            </table>

            <div class="warning-box">
                <h4>โ๏ธ ูุชู ูุณุชุฎุฏู ุฃู ุทุฑููุฉุ</h4>
                <ul>
                    <li><strong>Count Vectorization:</strong> ูุดุงุฑูุน ุจุณูุทุฉุ classification ุณุฑูุน</li>
                    <li><strong>TF-IDF:</strong> Information retrievalุ document similarity</li>
                    <li><strong>Word Embeddings:</strong> Deep learningุ semantic understanding</li>
                </ul>

                <p><strong>๐ก ูู ูุดุฑูุนูุง (Chatbot):</strong></p>
                <p>ุงุณุชุฎุฏููุง <strong>Word Embeddings</strong> ูุฃููุง:</p>
                <ul>
                    <li>ุชุญูุธ <strong>ุงูุณูุงู</strong></li>
                    <li>ุชููู <strong>ุงููุนูู</strong></li>
                    <li>ููุงุณุจุฉ ูู <strong>Sequence Generation</strong></li>
                </ul>
            </div>

            <!-- Summary -->
            <h3>๐ ุงูุฎูุงุตุฉ ุงูุนุงูุฉ - Old Tasks</h3>

            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Task</th>
                        <th>ุงููุฏู</th>
                        <th>ุงูุฃุฏูุงุช ุงููุณุชุฎุฏูุฉ</th>
                        <th>ุงููุงุฆุฏุฉ</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Syntax Features</strong></td>
                        <td>ููู ุงูุชุฑููุจ ุงููุญูู</td>
                        <td>โข Tokenization<br>โข POS Tagging<br>โข Noun Phrases<br>โข Parsing</td>
                        <td>ุชุญููู ุจููุฉ ุงูุฌููุฉ<br>ุงุณุชุฎุฑุงุฌ ูุนูููุงุช ูุญููุฉ</td>
                    </tr>
                    <tr>
                        <td><strong>Morphology</strong></td>
                        <td>ููู ุจููุฉ ุงููููุงุช</td>
                        <td>โข Lemmatization<br>โข Stemming<br>โข Word Inflection</td>
                        <td>ุฅุฑุฌุงุน ุงููููุงุช ูุฃุตููุง<br>ุชูููู ุงูููุฑุฏุงุช</td>
                    </tr>
                    <tr>
                        <td><strong>Vectorization</strong></td>
                        <td>ุชุญููู ุงููุต ูุฃุฑูุงู</td>
                        <td>โข Count Vectorizer<br>โข TF-IDF<br>โข (Word Embeddings)</td>
                        <td>ุชุฌููุฒ ุงูุจูุงูุงุช<br>ููู ML models</td>
                    </tr>
                </tbody>
            </table>

            <div class="success-box">
                <h4>๐ฏ ุงูุนูุงูุฉ ุจูุดุฑูุน ุงูู Chatbot:</h4>
                <ul>
                    <li><strong>Syntax:</strong> ุงุณุชุฎุฏููุง Tokenization ูู ูุนุงูุฌุฉ ุงูุจูุงูุงุช</li>
                    <li><strong>Morphology:</strong> ุงุณุชุฎุฏููุง preprocessing ูุชูุธูู ุงููุตูุต</li>
                    <li><strong>Vectorization:</strong> ุงุณุชุฎุฏููุง Embeddings (ุฃูุถู ูู TF-IDF ููู generation)</li>
                </ul>

                <p><strong>๐ก ุงููุฑู ุงูุฑุฆูุณู:</strong></p>
                <p>TextBlob ููุงุณุจ ูู <strong>ุชุญููู ุงููุตูุต ูุงูู Classification</strong></p>
                <p>ููู ูู <strong>Text Generation</strong>ุ ูุญุชุงุฌ ููุงุฐุฌ ุฃููู (Transformersุ GPT-2)</p>
            </div>

            <div class="info-box">
                <h4>๐ ุงููุฑุงุฌุน:</h4>
                <ul>
                    <li>TextBlob Official Documentation</li>
                    <li>NLTK Library</li>
                    <li>Scikit-learn Documentation</li>
                    <li>Penn Treebank POS Tags</li>
                    <li>WordNet Lemmatizer</li>
                </ul>
            </div>
        </section>




        <footer>
            <p>๐ ุชู ุฅูุดุงุก ูุฐุง ุงูุชูุซูู ููุดุฑูุน Text Generation</p>
            <p style="margin-top: 0.5rem;">๐ ุฏูุณูุจุฑ 2025</p>
        </footer>
    </div>

    <script>
        // Smooth scrolling for navigation links
        document.querySelectorAll('nav a').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                target.scrollIntoView({
                    behavior: 'smooth',
                    block: 'start'
                });
            });
        });

        // Add animation on scroll
        const observerOptions = {
            threshold: 0.1,
            rootMargin: '0px 0px -100px 0px'
        };

        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.style.opacity = '1';
                    entry.target.style.transform = 'translateY(0)';
                }
            });
        }, observerOptions);

        document.querySelectorAll('.section').forEach(section => {
            observer.observe(section);
        });
    </script>
</body>

</html>
